{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GoViral/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The symptoms included are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['intercept',\n",
    "            'fever',\n",
    "            'sorethroat',\n",
    "            'cough',\n",
    "            'muscle',\n",
    "            'headache',\n",
    "            'fatigue',\n",
    "            'vomit',\n",
    "            'nausea',\n",
    "            'diarrhea',\n",
    "            'chills',\n",
    "            'sneeze',\n",
    "            'shortness of breath',\n",
    "            'phlegm',\n",
    "            'blockednose',\n",
    "            'earache',\n",
    "            'leg pain',\n",
    "            'runnynose',\n",
    "            'virus']\n",
    "aucs_ = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'fever', 'sorethroat', 'cough', 'muscle', 'headache', 'fatigue', 'vomit', 'nausea', 'diarrhea', 'chills', 'sneeze', 'shortness of breath', 'phlegm', 'blockednose', 'earache', 'leg pain', 'runnynose', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data['intercept'] = 1\n",
    "    columns = list(data.columns)\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    data = data[columns]\n",
    "#     train_data = data.drop(['virus'],axis =1).as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_parameters(filename):\n",
    "    parameters = pd.read_csv(filename)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the parameters for the different dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_ = \"./Generated_Parameters_3/\"\n",
    "with_demographics_ = ['with_demographics_nyumc.csv','with_demographics_goviral.csv','with_demographics_fluwatch.csv','with_demographics_hongkong.csv','with_demographics_hutterite.csv']\n",
    "with_demographic_parameters = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_parameters(file,parameters_of):\n",
    "    param = read_parameters(file)\n",
    "    parameter_dict = defaultdict()\n",
    "    for i in parameters_of:\n",
    "        parameter_dict[i] = list(param[i])\n",
    "    return parameter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters(dataset_name,parameters):\n",
    "    return np.array(list(parameters[dataset_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(param,sample_points):\n",
    "    return sigmoid(np.dot(param,sample_points.T)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results_for_finding_threshold(filename,dataframe,predicted):\n",
    "    results = pd.DataFrame()\n",
    "    results['Actual'] = dataframe['virus']\n",
    "    results['Predicted'] = predicted\n",
    "    print(results.head())\n",
    "    results.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_datasets(training_data_,training_directory):\n",
    "    datasets = defaultdict()\n",
    "    for i in training_data_:\n",
    "        data = read_file(training_directory+i)\n",
    "        datasets[i[:-4]] = (data)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_results(data_dict,param):\n",
    "    results = defaultdict()\n",
    "    for i in list(param.keys()):\n",
    "        data,train = data_dict[i]\n",
    "        results[i] = get_results(param[i],train)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_statistics(list_):\n",
    "#     print(\"Min : \",min(list_))\n",
    "#     print(\"Max : \",max(list_))\n",
    "#     print(\"Mean : \",np.mean(list_))\n",
    "#     print(\"Standard Deviation : \",np.std(list_))\n",
    "    return min(list_),max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_class(threshold,list_):\n",
    "    ans = [1 if x >= threshold else 0 for x in list_]\n",
    "    return ans\n",
    "\n",
    "def metrics_pred(list1,list2):\n",
    "    f1 =f1_score(list1,list2)\n",
    "    precision = precision_score(list1,list2)\n",
    "    recall = recall_score(list1,list2)\n",
    "    accuracy = accuracy_score(list1,list2)\n",
    "    fpr,tpr,threshold = roc_curve(list1,list2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "#     print(\"f1 score : \",f1)\n",
    "#     print(\"Precision score : \",precision)\n",
    "#     print(\"Recall : \",recall)\n",
    "#     print(\"Accuracy : \",accuracy)\n",
    "#     print(\"Area under the curve : \",auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_threshold(min_,max_,list1,list2,step_size = 1e-3):\n",
    "    auc_thresholds = defaultdict()\n",
    "    value = min_\n",
    "    while value < max_:\n",
    "        auc_thresholds[value] = metrics_pred(list1,return_class(value,list2))\n",
    "        value += step_size\n",
    "    optimal_threshold = max(auc_thresholds.items(), key=lambda x: x[1]) \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_threshold(pred,true):\n",
    "    min_,max_ = result_statistics(pred)\n",
    "    threshold = find_threshold(min_,max_,true,pred)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_all_thresholds(results,data,y_true):\n",
    "    thresholds = defaultdict()\n",
    "    for i in list(data.keys()):\n",
    "        print(\"_____________________\")\n",
    "        min_,max_ = result_statistics(results[i])\n",
    "        \n",
    "        threshold = find_threshold(min_,max_,y_true[i],results[i])\n",
    "        print(\"Found threshold for : \",i)\n",
    "        thresholds[i] = threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(filename_,param,thresholds_):\n",
    "    aucs = defaultdict()\n",
    "    data,train = read_file(filename_)\n",
    "    for i in list(param.keys()):\n",
    "        test_results = get_results(param[i],train)\n",
    "        auc_ = metrics_pred(data['virus'],return_class(thresholds_[i][0],test_results))\n",
    "        aucs[i] = auc_\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_final_auc_scores(training_data_,training_directory,filename_,parameters):\n",
    "    data = get_all_datasets(training_data_)\n",
    "    results = get_all_results(data,parameters)\n",
    "    #find the thresholds\n",
    "    thresholds = return_all_thresholds(results,data)\n",
    "    #get the auc values\n",
    "    aucs_= test(filename_,parameters,thresholds)\n",
    "    return aucs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict(dict_):\n",
    "    temp = []\n",
    "    for k,v in dict_.items():\n",
    "        temp.append((k,v))\n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_symp = defaultdict()\n",
    "results_demo = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gender(dataframe_):\n",
    "    df = dataframe_[['male','female']]\n",
    "    temp = df.apply(lambda x:x.argmax(),axis =1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(dataframe_):\n",
    "    df = dataframe_[['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']]\n",
    "    temp = df.apply(lambda x: x.argmax(), axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "#         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "#         result = [p_data,p_collection,p_gender+p_age,p_population]\n",
    "        result = [p_data]\n",
    "\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coeff(X,Y):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 10)\n",
    "    lm.fit(x_train,y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "#     print(\"Accuracy :\",acc)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "#     print(\"AUC :\",auc_score)\n",
    "    coefficients = lm.coef_.tolist()[0]\n",
    "    print(\"Coefficients : \",coefficients)\n",
    "    intercept = lm.intercept_.tolist()[0]\n",
    "    return coefficients,intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(list_):\n",
    "    min_ = min(list_)\n",
    "    max_ = max(list_)\n",
    "    denom = max_ - min_\n",
    "    ans = [x-min_/denom for x in list_]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION_MODE = {'nyumc':'clinically_collected',\n",
    "                   'goviral':'individually_reported',\n",
    "                   'fluwatch':'individually_reported',\n",
    "                   'hongkong': 'health_worker',\n",
    "                   'hutterite':'health_worker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        temp = [i[1:] for i in prediction]\n",
    "        first = [i[0] for i in prediction]\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(temp,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(temp,np.array(weights[i][0]).T)+weights[i][1]+first)\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "    return weights,thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test(training_directory,filename_,parameters,weights,thresholds,collection_mode = COLLECTION_MODE):\n",
    "    aucs_ = defaultdict()\n",
    "    predictions = defaultdict()\n",
    "    test_data = get_all_datasets([filename_],training_directory)\n",
    "    name = filename_.split('.')[0]\n",
    "    print(\"Name : \",name) \n",
    "    data_ = test_data[name]\n",
    "    temp_age = get_age(data_)\n",
    "    temp_gender = get_gender(data_)\n",
    "    only_symp_data = data_[symptoms]\n",
    "    only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "    y_true = list(data_['virus'])\n",
    "    train_data_symp = only_symp_data.as_matrix()\n",
    "    for i in weights.keys():\n",
    "        print(\"Using the parameters of : \",i)\n",
    "        prediction = get_predictions(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        temp = [i[1:] for i in prediction]\n",
    "        first = [i[0] for i in prediction]\n",
    "        prediction = np.array(temp)\n",
    "        value = np.array(np.dot(temp,np.array(weights[i][0]).T)+weights[i][1]+first)\n",
    "        values = [sigmoid(i) for i in value]\n",
    "        predictions[i] = values\n",
    "    print(\"Got the predicitions from the different parameters\")\n",
    "    for i in weights.keys():\n",
    "        auc_ = metrics_pred(y_true,return_class(0.5,predictions[i]))\n",
    "        aucs_[i] = auc_\n",
    "        print(\"Found the auc for \",i)\n",
    "    return aucs_\n",
    "#         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for NYUMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'goviral.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['goviral', 'fluwatch', 'hongkong', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['goviral', 'fluwatch', 'hongkong', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics_nyumc.csv',cols)\n",
    "demo_nyumc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With demographics!\n"
     ]
    }
   ],
   "source": [
    "print(\"With demographics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goviral.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  goviral\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(416, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5941a09c48f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights_nyumc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresholds_nyumc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_nyumc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdemo_nyumc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-42f2cccb46da>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(training_data_list, training_directory, filename_, parameters, collection_mode)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'virus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mcoefficient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coeff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcoefficient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-d27fcd7fa90f>\u001b[0m in \u001b[0;36mget_coeff\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/GoViral/anaconda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m-> 1173\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/GoViral/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/GoViral/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    422\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 424\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(416, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "weights_nyumc,thresholds_nyumc = process(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.46863700526936658,\n",
       "             'goviral': 0.49558837588576343,\n",
       "             'hongkong': 0.31236773948702068,\n",
       "             'hutterite': 0.54074399029825071})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  goviral\n",
      "Using the parameters of :  goviral\n",
      "Using the parameters of :  fluwatch\n",
      "Using the parameters of :  hongkong\n",
      "Using the parameters of :  hutterite\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  goviral\n",
      "Found the auc for  fluwatch\n",
      "Found the auc for  hongkong\n",
      "Found the auc for  hutterite\n"
     ]
    }
   ],
   "source": [
    "aucs_nyumc = process_test(training_directory,filename_,demo_nyumc,weights_nyumc,thresholds_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.59736032196969702,\n",
       "             'goviral': 0.61943655303030298,\n",
       "             'hongkong': 0.64405776515151514,\n",
       "             'hutterite': 0.64607007575757569})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['goviral'] = aucs_nyumc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for Goviral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_goviral = ['nyumc.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'nyumc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nyumc', 'fluwatch', 'hongkong', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nyumc', 'fluwatch', 'hongkong', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_goviral = return_parameters(directory_+'with_demographics_goviral.csv',cols)\n",
    "demo_goviral.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyumc.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [12.135089068841012]\n",
      "Found threshold for  nyumc\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [1.745470276695118]\n",
      "Found threshold for  fluwatch\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [10.983963939409902]\n",
      "Found threshold for  hongkong\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [4.133872050130364]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_goviral,thresholds_goviral = process(training_data_goviral,training_directory,filename_,demo_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  nyumc\n",
      "Using the parameters of :  nyumc\n",
      "Using the parameters of :  fluwatch\n",
      "Using the parameters of :  hongkong\n",
      "Using the parameters of :  hutterite\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  nyumc\n",
      "Found the auc for  fluwatch\n",
      "Found the auc for  hongkong\n",
      "Found the auc for  hutterite\n"
     ]
    }
   ],
   "source": [
    "aucs_goviral1 = process_test(training_directory,filename_,demo_goviral,weights_goviral,thresholds_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.5,\n",
       "             'hongkong': 0.54590970326164812,\n",
       "             'hutterite': 0.5427801939659288,\n",
       "             'nyumc': 0.61626304572294199})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_goviral1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['nyumc'] = aucs_goviral1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Generating the results for fluwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_fluwatch = ['nyumc.csv','goviral.csv','hongkong.csv','hutterite.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hongkong.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nyumc', 'goviral', 'hongkong', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nyumc', 'goviral', 'hongkong', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_fluwatch = return_parameters(directory_+'with_demographics_fluwatch.csv',cols)\n",
    "demo_fluwatch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hongkong.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [12.135089068913969]\n",
      "Found threshold for  nyumc\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [2.7022152779745263]\n",
      "Found threshold for  goviral\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [10.983963939399228]\n",
      "Found threshold for  hongkong\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [4.133872050036544]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_fluwatch,thresholds_fluwatch = process(training_data_fluwatch,training_directory,filename_,demo_fluwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  hongkong\n",
      "Using the parameters of :  nyumc\n",
      "Using the parameters of :  goviral\n",
      "Using the parameters of :  hongkong\n",
      "Using the parameters of :  hutterite\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  nyumc\n",
      "Found the auc for  goviral\n",
      "Found the auc for  hongkong\n",
      "Found the auc for  hutterite\n"
     ]
    }
   ],
   "source": [
    "aucs_fluwatch1 = process_test(training_directory,filename_,demo_fluwatch,weights_fluwatch,thresholds_fluwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'goviral': 0.67409301993119553,\n",
       "             'hongkong': 0.86103136942038738,\n",
       "             'hutterite': 0.85938388687517098,\n",
       "             'nyumc': 0.51079817781590009})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_fluwatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['hongkong'] = aucs_fluwatch1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating the results for HongKong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_hongkong = ['nyumc.csv','goviral.csv','fluwatch.csv','hutterite.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hutterite.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nyumc', 'goviral', 'fluwatch', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nyumc', 'goviral', 'fluwatch', 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_hongkong = return_parameters(directory_+'with_demographics_hongkong.csv',cols)\n",
    "demo_hongkong.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [12.135089069052853]\n",
      "Found threshold for  nyumc\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [2.702215277827879]\n",
      "Found threshold for  goviral\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [1.7454702767922383]\n",
      "Found threshold for  fluwatch\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [4.133872050233447]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_hongkong,thresholds_hongkong = process(training_data_hongkong,training_directory,filename_,demo_hongkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  hutterite\n",
      "Using the parameters of :  nyumc\n",
      "Using the parameters of :  goviral\n",
      "Using the parameters of :  fluwatch\n",
      "Using the parameters of :  hutterite\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  nyumc\n",
      "Found the auc for  goviral\n",
      "Found the auc for  fluwatch\n",
      "Found the auc for  hutterite\n"
     ]
    }
   ],
   "source": [
    "aucs_hongkong = process_test(training_directory,filename_,demo_hongkong,weights_hongkong,thresholds_hongkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.5262923351158646,\n",
       "             'goviral': 0.51099598930481283,\n",
       "             'hutterite': 0.57973113487819372,\n",
       "             'nyumc': 0.51924762329174101})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['hutterite'] = aucs_hongkong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating results for hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_hutterite = ['nyumc.csv','goviral.csv','fluwatch.csv','hongkong.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'fluwatch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nyumc', 'goviral', 'fluwatch', 'hongkong', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nyumc', 'goviral', 'fluwatch', 'hongkong', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_hutterite = return_parameters(directory_+'with_demographics_hutterite.csv',cols)\n",
    "demo_hutterite.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluwatch.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [12.135089069195635]\n",
      "Found threshold for  nyumc\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [2.7022152775205974]\n",
      "Found threshold for  goviral\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [1.7454702766983732]\n",
      "Found threshold for  fluwatch\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [10.983963939432357]\n",
      "Found threshold for  hongkong\n"
     ]
    }
   ],
   "source": [
    "weights_hutterite,thresholds_hutterite = process(training_data_hutterite,training_directory,filename_,demo_hutterite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  fluwatch\n",
      "Using the parameters of :  nyumc\n",
      "Using the parameters of :  goviral\n",
      "Using the parameters of :  fluwatch\n",
      "Using the parameters of :  hongkong\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  nyumc\n",
      "Found the auc for  goviral\n",
      "Found the auc for  fluwatch\n",
      "Found the auc for  hongkong\n"
     ]
    }
   ],
   "source": [
    "aucs_hutterite = process_test(training_directory,filename_,demo_hutterite,weights_hutterite,thresholds_hutterite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.5424190141181644,\n",
       "             'goviral': 0.54253132856036779,\n",
       "             'hongkong': 0.52050097020560715,\n",
       "             'nyumc': 0.50119483449152624})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['fluwatch'] = aucs_hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': defaultdict(None,\n",
       "                         {'fluwatch': 0.5424190141181644,\n",
       "                          'goviral': 0.54253132856036779,\n",
       "                          'hongkong': 0.52050097020560715,\n",
       "                          'nyumc': 0.50119483449152624}),\n",
       "             'goviral': defaultdict(None,\n",
       "                         {'fluwatch': 0.59736032196969702,\n",
       "                          'goviral': 0.61943655303030298,\n",
       "                          'hongkong': 0.64405776515151514,\n",
       "                          'hutterite': 0.64607007575757569}),\n",
       "             'hongkong': defaultdict(None,\n",
       "                         {'goviral': 0.67409301993119553,\n",
       "                          'hongkong': 0.86103136942038738,\n",
       "                          'hutterite': 0.85938388687517098,\n",
       "                          'nyumc': 0.51079817781590009}),\n",
       "             'hutterite': defaultdict(None,\n",
       "                         {'fluwatch': 0.5262923351158646,\n",
       "                          'goviral': 0.51099598930481283,\n",
       "                          'hutterite': 0.57973113487819372,\n",
       "                          'nyumc': 0.51924762329174101}),\n",
       "             'nyumc': defaultdict(None,\n",
       "                         {'fluwatch': 0.5,\n",
       "                          'hongkong': 0.54590970326164812,\n",
       "                          'hutterite': 0.5427801939659288,\n",
       "                          'nyumc': 0.61626304572294199})})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_plots(columns,dict_,name,order,label,title):\n",
    "    df = pd.DataFrame()\n",
    "    df_list = []\n",
    "    for i in columns:\n",
    "        print(i)\n",
    "        df_list.append(pd.DataFrame({k:[v] for (k,v) in dict(dict_[i]).items()}))\n",
    "    df = pd.concat(df_list)\n",
    "#     df.fillna(0,inplace = True)\n",
    "    df[name] = columns\n",
    "    df.set_index(name,inplace = True)\n",
    "    df = df[order]\n",
    "    print(df)\n",
    "    sns.set()\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(df,annot=True,linewidth = 0.8,ax = ax,cbar_kws = {'label' : label},fmt=\"f\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted using datatset')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['fluwatch','hutterite','hongkong','nyumc','goviral'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['goviral','nyumc','hongkong','hutterite','fluwatch'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['nyumc','goviral','fluwatch','hongkong','hutterite'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['hutterite','hongkong','fluwatch','goviral','nyumc'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['nyumc','goviral','fluwatch','hongkong','hutterite'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['hutterite','hongkong','fluwatch','goviral','nyumc'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
