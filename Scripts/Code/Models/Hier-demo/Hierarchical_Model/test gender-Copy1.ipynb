{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The symptoms included are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['intercept',\n",
    "            'fever',\n",
    "            'sorethroat',\n",
    "            'cough',\n",
    "            'muscle',\n",
    "            'headache',\n",
    "            'fatigue',\n",
    "            'vomit',\n",
    "            'nausea',\n",
    "            'diarrhea',\n",
    "            'chills',\n",
    "            'sneeze',\n",
    "            'shortness of breath',\n",
    "            'phlegm',\n",
    "            'blockednose',\n",
    "            'earache',\n",
    "            'leg pain',\n",
    "            'runnynose',\n",
    "            'virus']\n",
    "aucs_ = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'fever', 'sorethroat', 'cough', 'muscle', 'headache', 'fatigue', 'vomit', 'nausea', 'diarrhea', 'chills', 'sneeze', 'shortness of breath', 'phlegm', 'blockednose', 'earache', 'leg pain', 'runnynose', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data['intercept'] = 1\n",
    "    columns = list(data.columns)\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    data = data[columns]\n",
    "#     train_data = data.drop(['virus'],axis =1).as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_parameters(filename):\n",
    "    parameters = pd.read_csv(filename)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the parameters for the different dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_ = \"./Generated_Parameters_Age/\"\n",
    "with_demographics_ = ['with_demographics','with_demographics_goviral.csv','with_demographics_fluwatch.csv','with_demographics_hongkong.csv','with_demographics_hutterite.csv']\n",
    "with_demographic_parameters = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_parameters(file,parameters_of):\n",
    "    param = read_parameters(file)\n",
    "    parameter_dict = defaultdict()\n",
    "    for i in parameters_of:\n",
    "        parameter_dict[i] = list(param[i])\n",
    "    return parameter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters(dataset_name,parameters):\n",
    "    return np.array(list(parameters[dataset_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(param,sample_points):\n",
    "    return sigmoid(np.dot(param,sample_points.T)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results_for_finding_threshold(filename,dataframe,predicted):\n",
    "    results = pd.DataFrame()\n",
    "    results['Actual'] = dataframe['virus']\n",
    "    results['Predicted'] = predicted\n",
    "    print(results.head())\n",
    "    results.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_datasets(training_data_,training_directory):\n",
    "    datasets = defaultdict()\n",
    "    for i in training_data_:\n",
    "        data = read_file(training_directory+i)\n",
    "        datasets[i[:-4]] = (data)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_results(data_dict,param):\n",
    "    results = defaultdict()\n",
    "    for i in list(param.keys()):\n",
    "        data,train = data_dict[i]\n",
    "        results[i] = get_results(param[i],train)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_statistics(list_):\n",
    "#     print(\"Min : \",min(list_))\n",
    "#     print(\"Max : \",max(list_))\n",
    "#     print(\"Mean : \",np.mean(list_))\n",
    "#     print(\"Standard Deviation : \",np.std(list_))\n",
    "    return min(list_),max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_class(threshold,list_):\n",
    "    ans = [1 if x >= threshold else 0 for x in list_]\n",
    "    return ans\n",
    "\n",
    "def metrics_pred(list1,list2):\n",
    "    f1 =f1_score(list1,list2)\n",
    "    precision = precision_score(list1,list2)\n",
    "    recall = recall_score(list1,list2)\n",
    "    accuracy = accuracy_score(list1,list2)\n",
    "    fpr,tpr,threshold = roc_curve(list1,list2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "#     print(\"f1 score : \",f1)\n",
    "#     print(\"Precision score : \",precision)\n",
    "#     print(\"Recall : \",recall)\n",
    "#     print(\"Accuracy : \",accuracy)\n",
    "#     print(\"Area under the curve : \",auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_threshold(min_,max_,list1,list2,step_size = 1e-3):\n",
    "    auc_thresholds = defaultdict()\n",
    "    value = min_\n",
    "    while value < max_:\n",
    "        auc_thresholds[value] = metrics_pred(list1,return_class(value,list2))\n",
    "        value += step_size\n",
    "    optimal_threshold = max(auc_thresholds.items(), key=lambda x: x[1]) \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_threshold(pred,true):\n",
    "    min_,max_ = result_statistics(pred)\n",
    "    threshold = find_threshold(min_,max_,true,pred)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_all_thresholds(results,data,y_true):\n",
    "    thresholds = defaultdict()\n",
    "    for i in list(data.keys()):\n",
    "        print(\"_____________________\")\n",
    "        min_,max_ = result_statistics(results[i])\n",
    "        \n",
    "        threshold = find_threshold(min_,max_,y_true[i],results[i])\n",
    "        print(\"Found threshold for : \",i)\n",
    "        thresholds[i] = threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(filename_,param,thresholds_):\n",
    "    aucs = defaultdict()\n",
    "    data,train = read_file(filename_)\n",
    "    for i in list(param.keys()):\n",
    "        test_results = get_results(param[i],train)\n",
    "        auc_ = metrics_pred(data['virus'],return_class(thresholds_[i][0],test_results))\n",
    "        aucs[i] = auc_\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_final_auc_scores(training_data_,training_directory,filename_,parameters):\n",
    "    data = get_all_datasets(training_data_)\n",
    "    results = get_all_results(data,parameters)\n",
    "    #find the thresholds\n",
    "    thresholds = return_all_thresholds(results,data)\n",
    "    #get the auc values\n",
    "    aucs_= test(filename_,parameters,thresholds)\n",
    "    return aucs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict(dict_):\n",
    "    temp = []\n",
    "    for k,v in dict_.items():\n",
    "        temp.append((k,v))\n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_symp = defaultdict()\n",
    "results_demo = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gender(dataframe_):\n",
    "    df = dataframe_[['male','female']]\n",
    "    temp = df.apply(lambda x:x.argmax(),axis =1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(dataframe_):\n",
    "    df = dataframe_[['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']]\n",
    "    temp = df.apply(lambda x: x.argmax(), axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_all(name,train,only_symp_age,only_symp_gender,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        result = []\n",
    "        sample_point = train[i,:]\n",
    "        gender = list(only_symp_gender.iloc[i][:])\n",
    "        age = list(only_symp_age.iloc[i][:])\n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "        result.append(p_data)\n",
    "#         result.append(gender[0]*get_results(param_dict['male'],sample_point))\n",
    "#         result.append(gender[1]*get_results(param_dict['female'],sample_point))\n",
    "\n",
    "        result.append(age[0]*get_results(param_dict['age 0-4'],sample_point))\n",
    "        result.append(age[1]*get_results(param_dict['age 5-15'],sample_point))\n",
    "        result.append(age[2]*get_results(param_dict['age 16-44'],sample_point))\n",
    "        result.append(age[3]*get_results(param_dict['age 45-64'],sample_point))\n",
    "        result.append(age[4]*get_results(param_dict['age 65+'],sample_point))\n",
    "        \n",
    "#         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "# #         p_population = get_results(param_dict[population],sample_point)\n",
    "#         result = [p_data,p_collection,p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_collection(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "#         p_data = get_results(param_dict[name],sample_point)\n",
    "        p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_collection]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_demographic(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "#         p_data = get_results(param_dict[name],sample_point)\n",
    "#         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "        p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "        p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_dataset(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "# #         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_data]\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coeff(X,Y):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 10)\n",
    "    lm.fit(x_train,y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "#     print(\"Accuracy :\",acc)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "#     print(\"AUC :\",auc_score)\n",
    "    coefficients = lm.coef_.tolist()[0]\n",
    "    print(\"Coefficients : \",coefficients)\n",
    "    intercept = lm.intercept_.tolist()[0]\n",
    "    return coefficients,intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(list_):\n",
    "    min_ = min(list_)\n",
    "    max_ = max(list_)\n",
    "    denom = max_ - min_\n",
    "    ans = [x-min_/denom for x in list_]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION_MODE = {'nyumc':'clinically_collected',\n",
    "                   'goviral':'individually_reported',\n",
    "                   'fluwatch':'individually_reported',\n",
    "                   'hongkong': 'health_worker',\n",
    "                   'hutterite':'health_worker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_gender = data_[['male','female']]\n",
    "        only_symp_age = data_[['age 0-4','age 5-15','age 16-44','age 45-64','age 65+']]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_all(i,train_data_symp,only_symp_age,only_symp_gender,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_only_dataset(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_dataset(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        values = [i[0] for i in prediction]\n",
    "#         coefficient,intercept = get_coeff(prediction,y_true)\n",
    "#         weights[i] = (coefficient,intercept)\n",
    "#         value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "#         values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_collection(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_collection(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_demographic(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_demographic(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test(training_directory,filename_,parameters,weights,thresholds,collection_mode = COLLECTION_MODE):\n",
    "    aucs_ = defaultdict()\n",
    "    predictions = defaultdict()\n",
    "    test_data = get_all_datasets([filename_],training_directory)\n",
    "    name = filename_.split('.')[0]\n",
    "    print(\"Name : \",name) \n",
    "    data_ = test_data[name]\n",
    "    temp_age = get_age(data_)\n",
    "    temp_gender = get_gender(data_)\n",
    "    only_symp_data = data_[symptoms]\n",
    "    only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "    y_true = list(data_['virus'])\n",
    "    train_data_symp = only_symp_data.as_matrix()\n",
    "    for i in weights.keys():\n",
    "        print(\"Using the parameters of : \",i)\n",
    "        prediction = get_predictions(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        temp = [i[1:] for i in prediction]\n",
    "        first = [i[0] for i in prediction]\n",
    "        prediction = np.array(temp)\n",
    "        value = np.array(np.dot(temp,np.array(weights[i][0]).T)+weights[i][1]+first)\n",
    "        values = [sigmoid(i) for i in value]\n",
    "        predictions[i] = values\n",
    "    print(\"Got the predicitions from the different parameters\")\n",
    "    for i in weights.keys():\n",
    "        auc_ = metrics_pred(y_true,return_class(0.5,predictions[i]))\n",
    "        aucs_[i] = auc_\n",
    "        print(\"Found the auc for \",i)\n",
    "    return aucs_\n",
    "#         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for HongKong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_goviral = ['goviral.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/Train/\"\n",
    "filename_ = 'goviral.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [ 'goviral', 'individually_reported', 'health_worker', 'age 0-4', 'age 5-15','age 16-44','age 45-64','age 65+','population']\n",
    "demo_goviral = return_parameters(directory_+'with_demographics.csv',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With demographics!\n"
     ]
    }
   ],
   "source": [
    "print(\"With demographics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goviral.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [-0.02443356372242698, 0.18274747741109207, 0.17654853261702605, -0.7143620738318895, 0.09806200715486992, 0.39024375421341206]\n",
      "Found threshold for  goviral\n"
     ]
    }
   ],
   "source": [
    "weights_all,thresholds_all,prediction_all = process_all(training_data_goviral,training_directory,filename_,demo_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'goviral': 0.46889127123859414})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.02443356372242698,\n",
       " 0.18274747741109207,\n",
       " 0.17654853261702605,\n",
       " -0.7143620738318895,\n",
       " 0.09806200715486992,\n",
       " 0.39024375421341206]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all['goviral'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['fluwatch.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/\"\n",
    "filename_ = 'fluwatch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [ 'fluwatch', 'individually_reported', 'health_worker', 'age 0-4', 'age 5-15','age 16-44','age 45-64','age 65+', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics.csv',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluwatch.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [0.039653287395670124, 0.6801684509430184, 0.7381600925249, 0.8990981423160382, -1.3515325032958443, -0.052516415015758086]\n",
      "Found threshold for  fluwatch\n"
     ]
    }
   ],
   "source": [
    "weights_all,thresholds_all,prediction_all = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.039653287395670124,\n",
       " 0.6801684509430184,\n",
       " 0.7381600925249,\n",
       " 0.8990981423160382,\n",
       " -1.3515325032958443,\n",
       " -0.052516415015758086]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all['fluwatch'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### fluwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['hongkong.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/\"\n",
    "filename_ = 'hongkong.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [ 'hongkong',  'individually_reported', 'health_worker', 'age 0-4', 'age 5-15','age 16-44','age 45-64','age 65+','population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics.csv',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hongkong.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [-3.328736920831443, 5.127491892701865, 2.6257243799801246, -8.206706086057912, -7.837791796360585, -6.7128082428705245]\n",
      "Found threshold for  hongkong\n"
     ]
    }
   ],
   "source": [
    "weights_all,thresholds_all,prediction_all = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.328736920831443,\n",
       " 5.127491892701865,\n",
       " 2.6257243799801246,\n",
       " -8.206706086057912,\n",
       " -7.837791796360585,\n",
       " -6.7128082428705245]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all['hongkong'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goviral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['hutterite.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/\"\n",
    "filename_ = 'hutterite.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['hutterite',  'individually_reported', 'health_worker', 'age 0-4', 'age 5-15','age 16-44','age 45-64','age 65+', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics.csv',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [-0.01520185504703568, 4.508603369786854, 0.7424670155881548, -1.7847774631305153, -2.52941033800328, -2.191276723598417]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_all,thresholds_all,prediction_all = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01520185504703568,\n",
       " 4.508603369786854,\n",
       " 0.7424670155881548,\n",
       " -1.7847774631305153,\n",
       " -2.52941033800328,\n",
       " -2.191276723598417]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all['hutterite'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def statistics(data):\n",
    "    male = data.loc[data['male']==1].shape[0]\n",
    "    female = data.loc[data['female']==1].shape[0]\n",
    "    age1 = data.loc[data['age 0-4']==1].shape[0]\n",
    "    age2 = data.loc[data['age 5-15']==1].shape[0]\n",
    "    age3 = data.loc[data['age 16-44']==1].shape[0]\n",
    "    age4 = data.loc[data['age 45-64']==1].shape[0]\n",
    "    age5 = data.loc[data['age 65+']==1].shape[0]\n",
    "    return (male,female,age1,age2,age3,age4,age5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nyumc = pd.read_csv(training_directory+'goviral.csv')\n",
    "data_nyumc = data_nyumc.loc[data_nyumc['virus']==1]\n",
    "nyumc_stats = statistics(data_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 150, 3, 0, 174, 57, 36)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyumc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nyumc = pd.read_csv(training_directory+'fluwatch.csv')\n",
    "data_nyumc = data_nyumc.loc[data_nyumc['virus']==1]\n",
    "nyumc_stats = statistics(data_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 314, 41, 79, 149, 230, 67)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyumc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nyumc = pd.read_csv(training_directory+'hongkong.csv')\n",
    "data_nyumc = data_nyumc.loc[data_nyumc['virus']==1]\n",
    "nyumc_stats = statistics(data_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(598, 873, 45, 367, 651, 295, 75)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyumc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_nyumc = pd.read_csv(training_directory+'hutterite.csv')\n",
    "data_nyumc = data_nyumc.loc[data_nyumc['virus']==1]\n",
    "nyumc_stats = statistics(data_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289, 498, 83, 256, 256, 113, 31)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyumc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['Predicted_Value_All'] = [i[1] for i in prediction_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Collection'] = [i[1] for i in prediction_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Demographic'] = [i[1] for i in prediction_demographic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Dataset'] = [i[1] for i in prediction_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['True'] = [i[0] for i in prediction_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value_All</th>\n",
       "      <th>Predicted_Value_Collection</th>\n",
       "      <th>Predicted_Value_Demographic</th>\n",
       "      <th>Predicted_Value_Dataset</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450453</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.452410</td>\n",
       "      <td>0.523619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.290858</td>\n",
       "      <td>0.297370</td>\n",
       "      <td>0.450590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698818</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.699158</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.741505</td>\n",
       "      <td>0.742480</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.700145</td>\n",
       "      <td>0.631536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.436980</td>\n",
       "      <td>0.458806</td>\n",
       "      <td>0.432685</td>\n",
       "      <td>0.512363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.699487</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.700034</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715776</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.713543</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.809162</td>\n",
       "      <td>0.794370</td>\n",
       "      <td>0.811930</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.471210</td>\n",
       "      <td>0.491998</td>\n",
       "      <td>0.467149</td>\n",
       "      <td>0.534053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Value_All  Predicted_Value_Collection  \\\n",
       "0             0.450453                    0.455603   \n",
       "1             0.290991                    0.290858   \n",
       "2             0.698818                    0.678647   \n",
       "3             0.742865                    0.741505   \n",
       "4             0.700064                    0.695279   \n",
       "5             0.436980                    0.458806   \n",
       "6             0.699487                    0.678647   \n",
       "7             0.715776                    0.727700   \n",
       "8             0.809162                    0.794370   \n",
       "9             0.471210                    0.491998   \n",
       "\n",
       "   Predicted_Value_Demographic  Predicted_Value_Dataset  True  \n",
       "0                     0.452410                 0.523619     1  \n",
       "1                     0.297370                 0.450590     0  \n",
       "2                     0.699158                 0.554041     1  \n",
       "3                     0.742480                 0.678333     1  \n",
       "4                     0.700145                 0.631536     1  \n",
       "5                     0.432685                 0.512363     0  \n",
       "6                     0.700034                 0.554041     1  \n",
       "7                     0.713543                 0.702055     1  \n",
       "8                     0.811930                 0.708987     1  \n",
       "9                     0.467149                 0.534053     1  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Dataset_Specific'] = weights_all['hutterite'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Collection_Mode'] = weights_all['hutterite'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions['Only_Dataset'] = weights_dataset['goviral'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Demographic'] = weights_all['hutterite'][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Only_Collection'] = weights_collection['hutterite'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Only_Demographic'] = weights_demographic['hutterite'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value_All</th>\n",
       "      <th>Predicted_Value_Collection</th>\n",
       "      <th>Predicted_Value_Demographic</th>\n",
       "      <th>Predicted_Value_Dataset</th>\n",
       "      <th>True</th>\n",
       "      <th>All_Dataset_Specific</th>\n",
       "      <th>All_Collection_Mode</th>\n",
       "      <th>All_Demographic</th>\n",
       "      <th>Only_Collection</th>\n",
       "      <th>Only_Demographic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450453</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.452410</td>\n",
       "      <td>0.523619</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.290858</td>\n",
       "      <td>0.297370</td>\n",
       "      <td>0.450590</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698818</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.699158</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.741505</td>\n",
       "      <td>0.742480</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.700145</td>\n",
       "      <td>0.631536</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.436980</td>\n",
       "      <td>0.458806</td>\n",
       "      <td>0.432685</td>\n",
       "      <td>0.512363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.699487</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.700034</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715776</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.713543</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.809162</td>\n",
       "      <td>0.794370</td>\n",
       "      <td>0.811930</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.471210</td>\n",
       "      <td>0.491998</td>\n",
       "      <td>0.467149</td>\n",
       "      <td>0.534053</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Value_All  Predicted_Value_Collection  \\\n",
       "0             0.450453                    0.455603   \n",
       "1             0.290991                    0.290858   \n",
       "2             0.698818                    0.678647   \n",
       "3             0.742865                    0.741505   \n",
       "4             0.700064                    0.695279   \n",
       "5             0.436980                    0.458806   \n",
       "6             0.699487                    0.678647   \n",
       "7             0.715776                    0.727700   \n",
       "8             0.809162                    0.794370   \n",
       "9             0.471210                    0.491998   \n",
       "\n",
       "   Predicted_Value_Demographic  Predicted_Value_Dataset  True  \\\n",
       "0                     0.452410                 0.523619     1   \n",
       "1                     0.297370                 0.450590     0   \n",
       "2                     0.699158                 0.554041     1   \n",
       "3                     0.742480                 0.678333     1   \n",
       "4                     0.700145                 0.631536     1   \n",
       "5                     0.432685                 0.512363     0   \n",
       "6                     0.700034                 0.554041     1   \n",
       "7                     0.713543                 0.702055     1   \n",
       "8                     0.811930                 0.708987     1   \n",
       "9                     0.467149                 0.534053     1   \n",
       "\n",
       "   All_Dataset_Specific  All_Collection_Mode  All_Demographic  \\\n",
       "0             -0.249233             0.751449          1.00933   \n",
       "1             -0.249233             0.751449          1.00933   \n",
       "2             -0.249233             0.751449          1.00933   \n",
       "3             -0.249233             0.751449          1.00933   \n",
       "4             -0.249233             0.751449          1.00933   \n",
       "5             -0.249233             0.751449          1.00933   \n",
       "6             -0.249233             0.751449          1.00933   \n",
       "7             -0.249233             0.751449          1.00933   \n",
       "8             -0.249233             0.751449          1.00933   \n",
       "9             -0.249233             0.751449          1.00933   \n",
       "\n",
       "   Only_Collection  Only_Demographic  \n",
       "0          2.68455           1.32303  \n",
       "1          2.68455           1.32303  \n",
       "2          2.68455           1.32303  \n",
       "3          2.68455           1.32303  \n",
       "4          2.68455           1.32303  \n",
       "5          2.68455           1.32303  \n",
       "6          2.68455           1.32303  \n",
       "7          2.68455           1.32303  \n",
       "8          2.68455           1.32303  \n",
       "9          2.68455           1.32303  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_csv(\"../Predictions/predictions_hutterite.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
