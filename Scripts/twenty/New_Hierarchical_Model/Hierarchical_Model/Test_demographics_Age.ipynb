{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The symptoms included are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['intercept',\n",
    "            'fever',\n",
    "            'sorethroat',\n",
    "            'cough',\n",
    "            'muscle',\n",
    "            'headache',\n",
    "            'fatigue',\n",
    "            'vomit',\n",
    "            'nausea',\n",
    "            'diarrhea',\n",
    "            'chills',\n",
    "            'sneeze',\n",
    "            'shortness of breath',\n",
    "            'phlegm',\n",
    "            'blockednose',\n",
    "            'earache',\n",
    "            'leg pain',\n",
    "            'runnynose',\n",
    "            'virus']\n",
    "aucs_ = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'fever', 'sorethroat', 'cough', 'muscle', 'headache', 'fatigue', 'vomit', 'nausea', 'diarrhea', 'chills', 'sneeze', 'shortness of breath', 'phlegm', 'blockednose', 'earache', 'leg pain', 'runnynose', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data['intercept'] = 1\n",
    "    columns = list(data.columns)\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    data = data[columns]\n",
    "#     train_data = data.drop(['virus'],axis =1).as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_parameters(filename):\n",
    "    parameters = pd.read_csv(filename)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the parameters for the different dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_ = \"./Parameters_Age/\"\n",
    "with_demographics_ = ['with_demographics_new.csv']\n",
    "with_demographic_parameters = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_parameters(file,parameters_of):\n",
    "    param = read_parameters(file)\n",
    "    parameter_dict = defaultdict()\n",
    "    for i in parameters_of:\n",
    "        parameter_dict[i] = list(param[i])\n",
    "    return parameter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters(dataset_name,parameters):\n",
    "    return np.array(list(parameters[dataset_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(param,sample_points):\n",
    "    return sigmoid(np.dot(param,sample_points.T)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results_for_finding_threshold(filename,dataframe,predicted):\n",
    "    results = pd.DataFrame()\n",
    "    results['Actual'] = dataframe['virus']\n",
    "    results['Predicted'] = predicted\n",
    "    print(results.head())\n",
    "    results.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_datasets(training_data_,training_directory):\n",
    "    datasets = defaultdict()\n",
    "    for i in training_data_:\n",
    "        data = read_file(training_directory+i)\n",
    "        datasets[i[:-4]] = (data)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_results(data_dict,param):\n",
    "    results = defaultdict()\n",
    "    for i in list(param.keys()):\n",
    "        data,train = data_dict[i]\n",
    "        results[i] = get_results(param[i],train)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_statistics(list_):\n",
    "#     print(\"Min : \",min(list_))\n",
    "#     print(\"Max : \",max(list_))\n",
    "#     print(\"Mean : \",np.mean(list_))\n",
    "#     print(\"Standard Deviation : \",np.std(list_))\n",
    "    return min(list_),max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_class(threshold,list_):\n",
    "    ans = [1 if x >= threshold else 0 for x in list_]\n",
    "    return ans\n",
    "\n",
    "def metrics_pred(list1,list2):\n",
    "    f1 =f1_score(list1,list2)\n",
    "    precision = precision_score(list1,list2)\n",
    "    recall = recall_score(list1,list2)\n",
    "    accuracy = accuracy_score(list1,list2)\n",
    "    fpr,tpr,threshold = roc_curve(list1,list2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "#     print(\"f1 score : \",f1)\n",
    "#     print(\"Precision score : \",precision)\n",
    "#     print(\"Recall : \",recall)\n",
    "#     print(\"Accuracy : \",accuracy)\n",
    "#     print(\"Area under the curve : \",auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_threshold(min_,max_,list1,list2,step_size = 1e-3):\n",
    "    auc_thresholds = defaultdict()\n",
    "    value = min_\n",
    "    while value < max_:\n",
    "        auc_thresholds[value] = metrics_pred(list1,return_class(value,list2))\n",
    "        value += step_size\n",
    "    optimal_threshold = max(auc_thresholds.items(), key=lambda x: x[1]) \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_threshold(pred,true):\n",
    "    min_,max_ = result_statistics(pred)\n",
    "    threshold = find_threshold(min_,max_,true,pred)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_all_thresholds(results,data,y_true):\n",
    "    thresholds = defaultdict()\n",
    "    for i in list(data.keys()):\n",
    "        print(\"_____________________\")\n",
    "        min_,max_ = result_statistics(results[i])\n",
    "        \n",
    "        threshold = find_threshold(min_,max_,y_true[i],results[i])\n",
    "        print(\"Found threshold for : \",i)\n",
    "        thresholds[i] = threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(filename_,param,thresholds_):\n",
    "    aucs = defaultdict()\n",
    "    data,train = read_file(filename_)\n",
    "    for i in list(param.keys()):\n",
    "        test_results = get_results(param[i],train)\n",
    "        auc_ = metrics_pred(data['virus'],return_class(thresholds_[i][0],test_results))\n",
    "        aucs[i] = auc_\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_final_auc_scores(training_data_,training_directory,filename_,parameters):\n",
    "    data = get_all_datasets(training_data_)\n",
    "    results = get_all_results(data,parameters)\n",
    "    #find the thresholds\n",
    "    thresholds = return_all_thresholds(results,data)\n",
    "    #get the auc values\n",
    "    aucs_= test(filename_,parameters,thresholds)\n",
    "    return aucs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict(dict_):\n",
    "    temp = []\n",
    "    for k,v in dict_.items():\n",
    "        temp.append((k,v))\n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_symp = defaultdict()\n",
    "results_demo = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gender(dataframe_):\n",
    "    df = dataframe_[['male','female']]\n",
    "    temp = df.apply(lambda x:x.argmax(),axis =1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(dataframe_):\n",
    "    df = dataframe_[['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']]\n",
    "    temp = df.apply(lambda x: x.argmax(), axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_all(name,train,only_symp_age,only_symp_gender,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        result = []\n",
    "        sample_point = train[i,:]\n",
    "        gender = list(only_symp_gender.iloc[i][:])\n",
    "        age = list(only_symp_age.iloc[i][:])\n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "        result.append(p_data)\n",
    "#         result.append(gender[0]*get_results(param_dict['male'],sample_point))\n",
    "#         result.append(gender[1]*get_results(param_dict['female'],sample_point))\n",
    "\n",
    "        result.append(age[0]*get_results(param_dict['age 0-4'],sample_point))\n",
    "        result.append(age[1]*get_results(param_dict['age 5-15'],sample_point))\n",
    "        result.append(age[2]*get_results(param_dict['age 16-44'],sample_point))\n",
    "        result.append(age[3]*get_results(param_dict['age 45-64'],sample_point))\n",
    "        result.append(age[4]*get_results(param_dict['age 65+'],sample_point))\n",
    "        \n",
    "#         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "# #         p_population = get_results(param_dict[population],sample_point)\n",
    "#         result = [p_data,p_collection,p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coeff(X,Y):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 10)\n",
    "    lm.fit(x_train,y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "#     print(\"Accuracy :\",acc)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "#     print(\"AUC :\",auc_score)\n",
    "    coefficients = lm.coef_.tolist()[0]\n",
    "    print(\"Coefficients : \",coefficients)\n",
    "    intercept = lm.intercept_.tolist()[0]\n",
    "    return coefficients,intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(list_):\n",
    "    min_ = min(list_)\n",
    "    max_ = max(list_)\n",
    "    denom = max_ - min_\n",
    "    ans = [x-min_/denom for x in list_]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION_MODE = {'nyumc':'clinically_collected',\n",
    "                   'goviral':'individually_reported',\n",
    "                   'fluwatch':'individually_reported',\n",
    "                   'hongkong': 'health_worker',\n",
    "                   'hutterite':'health_worker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_gender = data_[['male','female']]\n",
    "        only_symp_age = data_[['age 0-4','age 5-15','age 16-44','age 45-64','age 65+']]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_all(i,train_data_symp,only_symp_age,only_symp_gender,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        \n",
    "        \n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test(training_directory,filename_,parameters,weights,thresholds,collection_mode = COLLECTION_MODE):\n",
    "    aucs_ = defaultdict()\n",
    "    predictions = defaultdict()\n",
    "    test_data = get_all_datasets([filename_],training_directory)\n",
    "    name = filename_.split('.')[0]\n",
    "    print(\"Name : \",name) \n",
    "    data_ = test_data[name]\n",
    "    temp_age = get_age(data_)\n",
    "    temp_gender = get_gender(data_)\n",
    "    only_symp_data = data_[symptoms]\n",
    "    only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "    only_symp_gender = data_[['male','female']]\n",
    "    only_symp_age = data_[['age 0-4','age 5-15','age 16-44','age 45-64','age 65+']]\n",
    "    y_true = list(data_['virus'])\n",
    "    train_data_symp = only_symp_data.as_matrix()\n",
    "    for i in weights.keys():\n",
    "        print(\"Using the parameters of : \",i)\n",
    "        prediction = get_predictions_all(i,train_data_symp,only_symp_age,only_symp_gender,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "#         temp = [i[1:] for i in prediction]\n",
    "#         first = [i[0] for i in prediction]\n",
    "        prediction = np.array(prediction)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(i) for i in value]\n",
    "        predictions[i] = values\n",
    "   \n",
    "    print(\"Got the predicitions from the different parameters\")\n",
    "    for i in weights.keys():\n",
    "        auc_ = metrics_pred(y_true,return_class(thresholds[i],predictions[i]))\n",
    "        aucs_[i] = auc_\n",
    "        print(\"Found the auc for \",i)\n",
    "    return aucs_\n",
    "#         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for NYUMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['goviral.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Train/\"\n",
    "testing_directory = \"../../Data/Symptoms_Demo/Test/\"\n",
    "filename_ = 'goviral.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age 45-64', 'age 16-44', 'age 65+', 'age 0-4', 'population', 'individually_reported', 'age 5-15', 'goviral', 'health_worker'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['goviral',  'individually_reported', 'health_worker', 'age 0-4','age 5-15','age 16-44','age 45-64','age 65+', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics_new.csv',cols)\n",
    "demo_nyumc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With demographics!\n"
     ]
    }
   ],
   "source": [
    "print(\"With demographics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goviral.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [2.2169113027114857, 0.7529693784700504, -0.3176581623014775, 2.1155451345499166, 1.2440772444435613, 1.5097576564968958]\n",
      "Found threshold for  goviral\n"
     ]
    }
   ],
   "source": [
    "weights_nyumc,thresholds_nyumc,pred = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'goviral': 0.5745458310588295})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'goviral': ([2.2169113027114857,\n",
       "               0.7529693784700504,\n",
       "               -0.3176581623014775,\n",
       "               2.1155451345499166,\n",
       "               1.2440772444435613,\n",
       "               1.5097576564968958],\n",
       "              -2.41142767356107)})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  goviral\n",
      "Using the parameters of :  goviral\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  goviral\n"
     ]
    }
   ],
   "source": [
    "aucs_nyumc = process_test(testing_directory,filename_,demo_nyumc,weights_nyumc,thresholds_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'goviral': 0.6827671913835958})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['goviral'] = aucs_nyumc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for FluWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_goviral = ['fluwatch.csv']\n",
    "# training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/Train/\"\n",
    "filename_ = 'fluwatch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age 45-64', 'population', 'age 65+', 'age 0-4', 'individually_reported', 'fluwatch', 'age 5-15', 'age 16-44', 'health_worker'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['fluwatch',  'individually_reported', 'health_worker', 'age 0-4','age 5-15','age 16-44','age 45-64','age 65+', 'population']\n",
    "demo_goviral = return_parameters(directory_+'with_demographics_new.csv',cols)\n",
    "demo_goviral.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluwatch.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [0.3678178968555492, 0.6325855781707181, 0.7439766779519751, 0.4990589828294488, 0.8938304829036621, 0.9014762627864858]\n",
      "Found threshold for  fluwatch\n"
     ]
    }
   ],
   "source": [
    "weights_goviral,thresholds_goviral,ans = process_all(training_data_goviral,training_directory,filename_,demo_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  fluwatch\n",
      "Using the parameters of :  fluwatch\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  fluwatch\n"
     ]
    }
   ],
   "source": [
    "aucs_goviral1 = process_test(testing_directory,filename_,demo_goviral,weights_goviral,thresholds_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'fluwatch': 0.5860521562429442})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_goviral1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['nyumc'] = aucs_goviral1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Generating the results for hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_fluwatch = ['hongkong.csv']\n",
    "# training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hongkong.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age 45-64', 'hongkong', 'age 65+', 'age 0-4', 'population', 'individually_reported', 'age 5-15', 'age 16-44', 'health_worker'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['hongkong',  'individually_reported', 'health_worker', 'age 0-4','age 5-15','age 16-44','age 45-64','age 65+', 'population']\n",
    "demo_fluwatch = return_parameters(directory_+'with_demographics_new.csv',cols)\n",
    "demo_fluwatch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hongkong.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [0.30299531993630846, 6.210442628999582, 7.340794408257192, 7.558320157981965, 7.2541358649368135, 6.2621319748346815]\n",
      "Found threshold for  hongkong\n"
     ]
    }
   ],
   "source": [
    "weights_fluwatch,thresholds_fluwatch,ans = process_all(training_data_fluwatch,training_directory,filename_,demo_fluwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  hongkong\n",
      "Using the parameters of :  hongkong\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  hongkong\n"
     ]
    }
   ],
   "source": [
    "aucs_fluwatch1 = process_test(testing_directory,filename_,demo_fluwatch,weights_fluwatch,thresholds_fluwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hongkong': 0.9349961213722008})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_fluwatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['hongkong'] = aucs_fluwatch1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating the results for Hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_hongkong = ['hutterite.csv']\n",
    "# training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hutterite.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age 45-64', 'population', 'age 65+', 'age 0-4', 'individually_reported', 'age 5-15', 'age 16-44', 'hutterite', 'health_worker'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['hutterite',  'individually_reported', 'health_worker', 'age 0-4','age 5-15','age 16-44','age 45-64','age 65+', 'population']\n",
    "demo_hongkong = return_parameters(directory_+'with_demographics_new.csv',cols)\n",
    "demo_hongkong.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [1.9475855592665567, 1.3180521894619541, 1.7345791144586418, 1.5549686441273287, 2.183000572425849, 1.4018967820285873]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_hongkong,thresholds_hongkong,ans = process_all(training_data_hongkong,training_directory,filename_,demo_hongkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  hutterite\n",
      "Using the parameters of :  hutterite\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  hutterite\n"
     ]
    }
   ],
   "source": [
    "aucs_hongkong = process_test(testing_directory,filename_,demo_hongkong,weights_hongkong,thresholds_hongkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hutterite': 0.6947162426614482})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['hutterite'] = aucs_hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'goviral': defaultdict(None, {'goviral': 0.6827671913835958}),\n",
       "             'hongkong': defaultdict(None, {'hongkong': 0.9349961213722008}),\n",
       "             'hutterite': defaultdict(None, {'hutterite': 0.6947162426614482}),\n",
       "             'nyumc': defaultdict(None, {'fluwatch': 0.5860521562429442})})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_plots(columns,dict_,name,order,label,title):\n",
    "    df = pd.DataFrame()\n",
    "    df_list = []\n",
    "    for i in columns:\n",
    "        print(i)\n",
    "        df_list.append(pd.DataFrame({k:[v] for (k,v) in dict(dict_[i]).items()}))\n",
    "    df = pd.concat(df_list)\n",
    "#     df.fillna(0,inplace = True)\n",
    "    df[name] = columns\n",
    "    df.set_index(name,inplace = True)\n",
    "    df = df[order]\n",
    "    print(df)\n",
    "    sns.set()\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(df,annot=True,linewidth = 0.8,ax = ax,cbar_kws = {'label' : label},fmt=\"f\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted using datatset')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluwatch\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fluwatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-4b5fb7c7c82e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                      \u001b[0maucs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                      ['goviral','nyumc','hongkong','hutterite','fluwatch'],'AUC Scores ','Hierarchical : AUC scores with demographics')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-237-be22e4283b98>\u001b[0m in \u001b[0;36mcreate_plots\u001b[0;34m(columns, dict_, name, order, label, title)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     df.fillna(0,inplace = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fluwatch'"
     ]
    }
   ],
   "source": [
    "nyumc = create_plots(['fluwatch','hutterite','hongkong','nyumc','goviral'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['goviral','nyumc','hongkong','hutterite','fluwatch'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['nyumc','goviral','fluwatch','hongkong','hutterite'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['hutterite','hongkong','fluwatch','goviral','nyumc'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['nyumc','goviral','fluwatch','hongkong','hutterite'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['hutterite','hongkong','fluwatch','goviral','nyumc'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
