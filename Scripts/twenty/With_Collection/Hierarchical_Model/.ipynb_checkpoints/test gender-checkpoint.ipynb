{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GoViral/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The symptoms included are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['intercept',\n",
    "            'fever',\n",
    "            'sorethroat',\n",
    "            'cough',\n",
    "            'muscle',\n",
    "            'headache',\n",
    "            'fatigue',\n",
    "            'vomit',\n",
    "            'nausea',\n",
    "            'diarrhea',\n",
    "            'chills',\n",
    "            'sneeze',\n",
    "            'shortness of breath',\n",
    "            'phlegm',\n",
    "            'blockednose',\n",
    "            'earache',\n",
    "            'leg pain',\n",
    "            'runnynose',\n",
    "            'virus']\n",
    "aucs_ = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'fever', 'sorethroat', 'cough', 'muscle', 'headache', 'fatigue', 'vomit', 'nausea', 'diarrhea', 'chills', 'sneeze', 'shortness of breath', 'phlegm', 'blockednose', 'earache', 'leg pain', 'runnynose', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data['intercept'] = 1\n",
    "    columns = list(data.columns)\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    data = data[columns]\n",
    "#     train_data = data.drop(['virus'],axis =1).as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_parameters(filename):\n",
    "    parameters = pd.read_csv(filename)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the parameters for the different dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_ = \"./Generated_Parameters_3/\"\n",
    "with_demographics_ = ['with_demographics_nyumc.csv','with_demographics_goviral.csv','with_demographics_fluwatch.csv','with_demographics_hongkong.csv','with_demographics_hutterite.csv']\n",
    "with_demographic_parameters = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_parameters(file,parameters_of):\n",
    "    param = read_parameters(file)\n",
    "    parameter_dict = defaultdict()\n",
    "    for i in parameters_of:\n",
    "        parameter_dict[i] = list(param[i])\n",
    "    return parameter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters(dataset_name,parameters):\n",
    "    return np.array(list(parameters[dataset_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(param,sample_points):\n",
    "    return sigmoid(np.dot(param,sample_points.T)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results_for_finding_threshold(filename,dataframe,predicted):\n",
    "    results = pd.DataFrame()\n",
    "    results['Actual'] = dataframe['virus']\n",
    "    results['Predicted'] = predicted\n",
    "    print(results.head())\n",
    "    results.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_datasets(training_data_,training_directory):\n",
    "    datasets = defaultdict()\n",
    "    for i in training_data_:\n",
    "        data = read_file(training_directory+i)\n",
    "        datasets[i[:-4]] = (data)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_results(data_dict,param):\n",
    "    results = defaultdict()\n",
    "    for i in list(param.keys()):\n",
    "        data,train = data_dict[i]\n",
    "        results[i] = get_results(param[i],train)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_statistics(list_):\n",
    "#     print(\"Min : \",min(list_))\n",
    "#     print(\"Max : \",max(list_))\n",
    "#     print(\"Mean : \",np.mean(list_))\n",
    "#     print(\"Standard Deviation : \",np.std(list_))\n",
    "    return min(list_),max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_class(threshold,list_):\n",
    "    ans = [1 if x >= threshold else 0 for x in list_]\n",
    "    return ans\n",
    "\n",
    "def metrics_pred(list1,list2):\n",
    "    f1 =f1_score(list1,list2)\n",
    "    precision = precision_score(list1,list2)\n",
    "    recall = recall_score(list1,list2)\n",
    "    accuracy = accuracy_score(list1,list2)\n",
    "    fpr,tpr,threshold = roc_curve(list1,list2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "#     print(\"f1 score : \",f1)\n",
    "#     print(\"Precision score : \",precision)\n",
    "#     print(\"Recall : \",recall)\n",
    "#     print(\"Accuracy : \",accuracy)\n",
    "#     print(\"Area under the curve : \",auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_threshold(min_,max_,list1,list2,step_size = 1e-3):\n",
    "    auc_thresholds = defaultdict()\n",
    "    value = min_\n",
    "    while value < max_:\n",
    "        auc_thresholds[value] = metrics_pred(list1,return_class(value,list2))\n",
    "        value += step_size\n",
    "    optimal_threshold = max(auc_thresholds.items(), key=lambda x: x[1]) \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_threshold(pred,true):\n",
    "    min_,max_ = result_statistics(pred)\n",
    "    threshold = find_threshold(min_,max_,true,pred)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_all_thresholds(results,data,y_true):\n",
    "    thresholds = defaultdict()\n",
    "    for i in list(data.keys()):\n",
    "        print(\"_____________________\")\n",
    "        min_,max_ = result_statistics(results[i])\n",
    "        \n",
    "        threshold = find_threshold(min_,max_,y_true[i],results[i])\n",
    "        print(\"Found threshold for : \",i)\n",
    "        thresholds[i] = threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(filename_,param,thresholds_):\n",
    "    aucs = defaultdict()\n",
    "    data,train = read_file(filename_)\n",
    "    for i in list(param.keys()):\n",
    "        test_results = get_results(param[i],train)\n",
    "        auc_ = metrics_pred(data['virus'],return_class(thresholds_[i][0],test_results))\n",
    "        aucs[i] = auc_\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_final_auc_scores(training_data_,training_directory,filename_,parameters):\n",
    "    data = get_all_datasets(training_data_)\n",
    "    results = get_all_results(data,parameters)\n",
    "    #find the thresholds\n",
    "    thresholds = return_all_thresholds(results,data)\n",
    "    #get the auc values\n",
    "    aucs_= test(filename_,parameters,thresholds)\n",
    "    return aucs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict(dict_):\n",
    "    temp = []\n",
    "    for k,v in dict_.items():\n",
    "        temp.append((k,v))\n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_symp = defaultdict()\n",
    "results_demo = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gender(dataframe_):\n",
    "    df = dataframe_[['male','female']]\n",
    "    temp = df.apply(lambda x:x.argmax(),axis =1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(dataframe_):\n",
    "    df = dataframe_[['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']]\n",
    "    temp = df.apply(lambda x: x.argmax(), axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_all(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        result = []\n",
    "        sample_point = train[i,:]\n",
    "        \n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "        p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "        p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "        p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_data,p_collection,p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_collection(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "#         p_data = get_results(param_dict[name],sample_point)\n",
    "        p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_collection]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_demographic(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "#         p_data = get_results(param_dict[name],sample_point)\n",
    "#         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "        p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "        p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_dataset(name,train,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        sample_point = train[i,:]\n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "# #         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        result = [p_data]\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coeff(X,Y):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 10)\n",
    "    lm.fit(x_train,y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "#     print(\"Accuracy :\",acc)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "#     print(\"AUC :\",auc_score)\n",
    "    coefficients = lm.coef_.tolist()[0]\n",
    "    print(\"Coefficients : \",coefficients)\n",
    "    intercept = lm.intercept_.tolist()[0]\n",
    "    return coefficients,intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(list_):\n",
    "    min_ = min(list_)\n",
    "    max_ = max(list_)\n",
    "    denom = max_ - min_\n",
    "    ans = [x-min_/denom for x in list_]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION_MODE = {'nyumc':'clinically_collected',\n",
    "                   'goviral':'individually_reported',\n",
    "                   'fluwatch':'individually_reported',\n",
    "                   'hongkong': 'health_worker',\n",
    "                   'hutterite':'health_worker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_gender = data_[['male','female']]\n",
    "        only_symp_age = data_[['age 0-4','age 5-15','age 16-44','age 45-64','age 65+']]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_all(i,train_data_symp,only_symp_age,only_symp_gender,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_only_dataset(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_dataset(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        values = [i[0] for i in prediction]\n",
    "#         coefficient,intercept = get_coeff(prediction,y_true)\n",
    "#         weights[i] = (coefficient,intercept)\n",
    "#         value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "#         values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_collection(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_collection(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_demographic(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_demographic(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test(training_directory,filename_,parameters,weights,thresholds,collection_mode = COLLECTION_MODE):\n",
    "    aucs_ = defaultdict()\n",
    "    predictions = defaultdict()\n",
    "    test_data = get_all_datasets([filename_],training_directory)\n",
    "    name = filename_.split('.')[0]\n",
    "    print(\"Name : \",name) \n",
    "    data_ = test_data[name]\n",
    "    temp_age = get_age(data_)\n",
    "    temp_gender = get_gender(data_)\n",
    "    only_symp_data = data_[symptoms]\n",
    "    only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "    y_true = list(data_['virus'])\n",
    "    train_data_symp = only_symp_data.as_matrix()\n",
    "    for i in weights.keys():\n",
    "        print(\"Using the parameters of : \",i)\n",
    "        prediction = get_predictions(i,train_data_symp,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        temp = [i[1:] for i in prediction]\n",
    "        first = [i[0] for i in prediction]\n",
    "        prediction = np.array(temp)\n",
    "        value = np.array(np.dot(temp,np.array(weights[i][0]).T)+weights[i][1]+first)\n",
    "        values = [sigmoid(i) for i in value]\n",
    "        predictions[i] = values\n",
    "    print(\"Got the predicitions from the different parameters\")\n",
    "    for i in weights.keys():\n",
    "        auc_ = metrics_pred(y_true,return_class(0.5,predictions[i]))\n",
    "        aucs_[i] = auc_\n",
    "        print(\"Found the auc for \",i)\n",
    "    return aucs_\n",
    "#         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for HongKong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['hutterite.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hutterite.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [ 'hutterite', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics_nyumc.csv',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With demographics!\n"
     ]
    }
   ],
   "source": [
    "print(\"With demographics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [-0.24923267574120045, 0.7514492220153693, 1.0093303316564344]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_all,thresholds_all,prediction_all = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hutterite': 0.45167561798852102})"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.24923267574120045, 0.7514492220153693, 1.0093303316564344]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all['hutterite'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demographic level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [1.3230295823989966]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_demographic,thresholds_demographic,prediction_demographic = process_demographic(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3230295823989966]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_demographic['hutterite'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hutterite': 0.45195682752629851})"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_demographic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collection level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [2.6845498822319667]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_collection,thresholds_collection,prediction_collection = process_collection(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.6845498822319667]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_collection['hutterite'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hutterite': 0.46220100944123826})"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_dataset,thresholds_dataset,prediction_dataset = process_only_dataset(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hutterite': 0.53104347720482292})"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['Predicted_Value_All'] = [i[1] for i in prediction_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Collection'] = [i[1] for i in prediction_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Demographic'] = [i[1] for i in prediction_demographic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Dataset'] = [i[1] for i in prediction_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['True'] = [i[0] for i in prediction_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value_All</th>\n",
       "      <th>Predicted_Value_Collection</th>\n",
       "      <th>Predicted_Value_Demographic</th>\n",
       "      <th>Predicted_Value_Dataset</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450453</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.452410</td>\n",
       "      <td>0.523619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.290858</td>\n",
       "      <td>0.297370</td>\n",
       "      <td>0.450590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698818</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.699158</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.741505</td>\n",
       "      <td>0.742480</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.700145</td>\n",
       "      <td>0.631536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.436980</td>\n",
       "      <td>0.458806</td>\n",
       "      <td>0.432685</td>\n",
       "      <td>0.512363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.699487</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.700034</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715776</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.713543</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.809162</td>\n",
       "      <td>0.794370</td>\n",
       "      <td>0.811930</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.471210</td>\n",
       "      <td>0.491998</td>\n",
       "      <td>0.467149</td>\n",
       "      <td>0.534053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Value_All  Predicted_Value_Collection  \\\n",
       "0             0.450453                    0.455603   \n",
       "1             0.290991                    0.290858   \n",
       "2             0.698818                    0.678647   \n",
       "3             0.742865                    0.741505   \n",
       "4             0.700064                    0.695279   \n",
       "5             0.436980                    0.458806   \n",
       "6             0.699487                    0.678647   \n",
       "7             0.715776                    0.727700   \n",
       "8             0.809162                    0.794370   \n",
       "9             0.471210                    0.491998   \n",
       "\n",
       "   Predicted_Value_Demographic  Predicted_Value_Dataset  True  \n",
       "0                     0.452410                 0.523619     1  \n",
       "1                     0.297370                 0.450590     0  \n",
       "2                     0.699158                 0.554041     1  \n",
       "3                     0.742480                 0.678333     1  \n",
       "4                     0.700145                 0.631536     1  \n",
       "5                     0.432685                 0.512363     0  \n",
       "6                     0.700034                 0.554041     1  \n",
       "7                     0.713543                 0.702055     1  \n",
       "8                     0.811930                 0.708987     1  \n",
       "9                     0.467149                 0.534053     1  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Dataset_Specific'] = weights_all['hutterite'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Collection_Mode'] = weights_all['hutterite'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions['Only_Dataset'] = weights_dataset['goviral'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Demographic'] = weights_all['hutterite'][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Only_Collection'] = weights_collection['hutterite'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Only_Demographic'] = weights_demographic['hutterite'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value_All</th>\n",
       "      <th>Predicted_Value_Collection</th>\n",
       "      <th>Predicted_Value_Demographic</th>\n",
       "      <th>Predicted_Value_Dataset</th>\n",
       "      <th>True</th>\n",
       "      <th>All_Dataset_Specific</th>\n",
       "      <th>All_Collection_Mode</th>\n",
       "      <th>All_Demographic</th>\n",
       "      <th>Only_Collection</th>\n",
       "      <th>Only_Demographic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.450453</td>\n",
       "      <td>0.455603</td>\n",
       "      <td>0.452410</td>\n",
       "      <td>0.523619</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.290991</td>\n",
       "      <td>0.290858</td>\n",
       "      <td>0.297370</td>\n",
       "      <td>0.450590</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698818</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.699158</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742865</td>\n",
       "      <td>0.741505</td>\n",
       "      <td>0.742480</td>\n",
       "      <td>0.678333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700064</td>\n",
       "      <td>0.695279</td>\n",
       "      <td>0.700145</td>\n",
       "      <td>0.631536</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.436980</td>\n",
       "      <td>0.458806</td>\n",
       "      <td>0.432685</td>\n",
       "      <td>0.512363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.699487</td>\n",
       "      <td>0.678647</td>\n",
       "      <td>0.700034</td>\n",
       "      <td>0.554041</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.715776</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.713543</td>\n",
       "      <td>0.702055</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.809162</td>\n",
       "      <td>0.794370</td>\n",
       "      <td>0.811930</td>\n",
       "      <td>0.708987</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.471210</td>\n",
       "      <td>0.491998</td>\n",
       "      <td>0.467149</td>\n",
       "      <td>0.534053</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.249233</td>\n",
       "      <td>0.751449</td>\n",
       "      <td>1.00933</td>\n",
       "      <td>2.68455</td>\n",
       "      <td>1.32303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Value_All  Predicted_Value_Collection  \\\n",
       "0             0.450453                    0.455603   \n",
       "1             0.290991                    0.290858   \n",
       "2             0.698818                    0.678647   \n",
       "3             0.742865                    0.741505   \n",
       "4             0.700064                    0.695279   \n",
       "5             0.436980                    0.458806   \n",
       "6             0.699487                    0.678647   \n",
       "7             0.715776                    0.727700   \n",
       "8             0.809162                    0.794370   \n",
       "9             0.471210                    0.491998   \n",
       "\n",
       "   Predicted_Value_Demographic  Predicted_Value_Dataset  True  \\\n",
       "0                     0.452410                 0.523619     1   \n",
       "1                     0.297370                 0.450590     0   \n",
       "2                     0.699158                 0.554041     1   \n",
       "3                     0.742480                 0.678333     1   \n",
       "4                     0.700145                 0.631536     1   \n",
       "5                     0.432685                 0.512363     0   \n",
       "6                     0.700034                 0.554041     1   \n",
       "7                     0.713543                 0.702055     1   \n",
       "8                     0.811930                 0.708987     1   \n",
       "9                     0.467149                 0.534053     1   \n",
       "\n",
       "   All_Dataset_Specific  All_Collection_Mode  All_Demographic  \\\n",
       "0             -0.249233             0.751449          1.00933   \n",
       "1             -0.249233             0.751449          1.00933   \n",
       "2             -0.249233             0.751449          1.00933   \n",
       "3             -0.249233             0.751449          1.00933   \n",
       "4             -0.249233             0.751449          1.00933   \n",
       "5             -0.249233             0.751449          1.00933   \n",
       "6             -0.249233             0.751449          1.00933   \n",
       "7             -0.249233             0.751449          1.00933   \n",
       "8             -0.249233             0.751449          1.00933   \n",
       "9             -0.249233             0.751449          1.00933   \n",
       "\n",
       "   Only_Collection  Only_Demographic  \n",
       "0          2.68455           1.32303  \n",
       "1          2.68455           1.32303  \n",
       "2          2.68455           1.32303  \n",
       "3          2.68455           1.32303  \n",
       "4          2.68455           1.32303  \n",
       "5          2.68455           1.32303  \n",
       "6          2.68455           1.32303  \n",
       "7          2.68455           1.32303  \n",
       "8          2.68455           1.32303  \n",
       "9          2.68455           1.32303  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_csv(\"../Predictions/predictions_hutterite.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
