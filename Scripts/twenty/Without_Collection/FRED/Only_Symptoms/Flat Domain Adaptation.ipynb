{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flat Domain adaptation, one dataset is held out, the model is trained on the remaining four datasets. Prediction is done using the parameters of the dataset that is closest to the held out one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['fever','cough','muscle','sorethroat','virus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "hongkong.csv\n",
      "loeb.csv\n",
      "fluwatch.csv\n",
      "hutterite.csv\n",
      "goviral.csv\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIRECTORY = \"../../../Data/Symptoms_Demo/Goviral/Train/\"\n",
    "TEST_DIRECTORY = \"../../../Data/Symptoms_Demo/Goviral/Test/\"\n",
    "for fn in os.listdir(TRAIN_DIRECTORY):\n",
    "    print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAIN_DIRECTORY = \"../../../Data/Symptoms_Demo/Goviral/Train/\"\n",
    "# TEST_DIRECTORY = \"../../../Data/Symptoms_Demo/Goviral/Test/\"\n",
    "coefficients = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "#     data = data[symptoms]\n",
    "#     print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(files_):\n",
    "    data = defaultdict()\n",
    "    columns = defaultdict()\n",
    "    for i in files_:\n",
    "        name = i\n",
    "        name = name.replace('.csv','')\n",
    "        data[name] = read_file(TRAIN_DIRECTORY+i)\n",
    "        columns[name] = list(data[name].columns)\n",
    "        columns[name].remove('virus')\n",
    "    return data,columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlap_columns(columns_):\n",
    "    all_columns = list(columns_.values())\n",
    "    overlap = list(set(all_columns[0]) & set(all_columns[1]) & set(all_columns[2]) & set(all_columns[3]))\n",
    "    return overlap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_columns(columns_):\n",
    "    overlap = overlap_columns(columns_)\n",
    "    new_columns = []\n",
    "    temp = []\n",
    "    for i in columns_.keys():\n",
    "        x = [i.replace('.csv','')+'_'+j for j in columns_[i]]\n",
    "        temp.append(x)\n",
    "    t = [val for sublist in temp for val in sublist]\n",
    "    new_columns = t + overlap\n",
    "    new_columns.append('virus')\n",
    "    return new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_dataframe(data,columns):\n",
    "    new_columns = create_columns(columns)\n",
    "    new_dataset = defaultdict()\n",
    "    for i,name in enumerate(data.keys()):\n",
    "        new_data = pd.DataFrame(columns=new_columns)\n",
    "        dataset = data[name]\n",
    "        for j in columns[name]:\n",
    "            new_data[name+'_'+j] = dataset[j]\n",
    "            new_data[j] = dataset[j]\n",
    "        new_data['virus'] = dataset['virus']\n",
    "        new_data.fillna(0,inplace=True)\n",
    "        new_dataset[name] = new_data\n",
    "    #concatenate all the dataframe\n",
    "    new_dataset = pd.concat(new_dataset.values())\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ml_model(dataset):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train = dataset.drop(['virus'],axis = 1)\n",
    "    y_train = dataset['virus']\n",
    "    x = lm.fit(x_train,y_train)\n",
    "    coeff = x.coef_.tolist()[0]\n",
    "    return lm,coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout dataset : NYUMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_nyumc = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "# data_nyumc,columns_nyumc = get_training_data(files_nyumc)\n",
    "\n",
    "# #create the dataframe for domain adaptation\n",
    "# new_dataset_nyumc = create_new_dataframe(data_nyumc,columns_nyumc)\n",
    "\n",
    "# coeff_without_nyumc = ml_model(new_dataset_nyumc)\n",
    "# coefficients['nyumc'] = coeff_without_nyumc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout dataset : Goviral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_goviral = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "\n",
    "\n",
    "data_goviral,columns_goviral = get_training_data(files_goviral)\n",
    "new_dataset_goviral = create_new_dataframe(data_goviral,columns_goviral)\n",
    "\n",
    "coeff_without_goviral = ml_model(new_dataset_goviral)\n",
    "coefficients['goviral'] = coeff_without_goviral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout dataset : FluWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_fluwatch = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "# data_fluwatch,columns_fluwatch = get_training_data(files_fluwatch)\n",
    "# new_dataset_fluwatch = create_new_dataframe(data_fluwatch,columns_fluwatch)\n",
    "\n",
    "# coeff_without_fluwatch = ml_model(new_dataset_fluwatch)\n",
    "# coefficients['fluwatch'] = coeff_without_fluwatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout dataset : HongKong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_hongkong = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "# data_hongkong,columns_hongkong = get_training_data(files_hongkong)\n",
    "# new_dataset_hongkong = create_new_dataframe(data_hongkong,columns_hongkong)\n",
    "\n",
    "# coeff_without_hongkong = ml_model(new_dataset_hongkong)\n",
    "# coefficients['hongkong'] = coeff_without_hongkong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heldout dataset : Hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_hutterite = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv']\n",
    "# data_hutterite,columns_hutterite = get_training_data(files_hutterite)\n",
    "# new_dataset_hutterite = create_new_dataframe(data_hutterite,columns_hutterite)\n",
    "\n",
    "# coeff_without_hutterite = ml_model(new_dataset_hutterite)\n",
    "# coefficients['hutterite'] = coeff_without_hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the target variable\n",
    "def remove_target(data_dict):\n",
    "    for i in data_dict.keys():\n",
    "        data_dict[i].drop(['virus'],axis = 1,inplace = True)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loeb', 'goviral', 'hongkong', 'fluwatch', 'hutterite'])\n"
     ]
    }
   ],
   "source": [
    "#get the entire training data\n",
    "files_ = ['goviral.csv','fluwatch.csv','hongkong.csv','hutterite.csv','loeb.csv']\n",
    "data_,columns_ = get_training_data(files_)\n",
    "print(data_.keys())\n",
    "data_ = remove_target(data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model for testing the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(train_data,test_data):\n",
    "    lm,coeff = ml_model(train_data)\n",
    "    train = test_data.drop(['virus'],axis = 1)\n",
    "    test = test_data['virus']\n",
    "    y_pred = lm.predict(train)\n",
    "    acc = accuracy_score(test,y_pred)\n",
    "    fpr,tpr,threshold = roc_curve(test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "    return acc,auc_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_,columns = get_training_data(files_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_for_testing(data,name,columns_):\n",
    "    new_data = pd.DataFrame(columns = columns_)\n",
    "    columns_for_data = list(data.columns)\n",
    "    col = [x for x in columns_for_data if x != 'virus']\n",
    "    for i in col:\n",
    "        new_data[name+'_'+i] = data[i]\n",
    "        new_data[i] = data[i]\n",
    "    new_data['virus'] = data['virus']\n",
    "    new_data.fillna(0,inplace = True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_against_all(dataset_name,to_be_tested_names,data_,original_data,store_):\n",
    "    columns = list(original_data.columns)\n",
    "    data = data_[dataset_name]\n",
    "    for i in to_be_tested_names:\n",
    "        temp_data = create_data_for_testing(data,i,columns)\n",
    "        acc,auc_score = test_model(original_data,temp_data)\n",
    "        print(\"Comparing against \",i)\n",
    "        print(\"Accuracy : \",acc)\n",
    "        print(\"Auc Score : \",auc_score)\n",
    "        print(\"____________________________\")\n",
    "        store_[i] = auc_score\n",
    "    return store_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test NYUMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store_nyumc = defaultdict()\n",
    "# print(\"Testing NYUMC Data!\\n\")\n",
    "# store_nyumc = test_against_all('nyumc',['goviral','fluwatch','hongkong','hutterite'],data_,new_dataset_nyumc,store_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store_nyumc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Goviral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Goviral data!\n",
      "\n",
      "Comparing against  goviral\n",
      "Accuracy :  0.7447306791569087\n",
      "Auc Score :  0.7543104083286272\n",
      "____________________________\n",
      "Comparing against  fluwatch\n",
      "Accuracy :  0.615144418423107\n",
      "Auc Score :  0.6288641441795368\n",
      "____________________________\n",
      "Comparing against  hongkong\n",
      "Accuracy :  0.7080405932864949\n",
      "Auc Score :  0.7262516266850002\n",
      "____________________________\n",
      "Comparing against  hutterite\n",
      "Accuracy :  0.8930523028883685\n",
      "Auc Score :  0.8920715986937412\n",
      "____________________________\n"
     ]
    }
   ],
   "source": [
    "store_gv = defaultdict()\n",
    "print(\"Testing Goviral data!\\n\")\n",
    "store_gv = test_against_all('hutterite',['goviral','fluwatch','hongkong','hutterite'],data_,new_dataset_goviral,store_gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.6288641441795368,\n",
       "             'goviral': 0.7543104083286272,\n",
       "             'hongkong': 0.7262516266850002,\n",
       "             'hutterite': 0.8920715986937412})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_gv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Fluwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing FluWatch data!\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_dataset_fluwatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e28bc0842572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstore_fw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing FluWatch data!\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstore_fw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_against_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fluwatch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fluwatch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'goviral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hongkong'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hutterite'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_dataset_fluwatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_fw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'new_dataset_fluwatch' is not defined"
     ]
    }
   ],
   "source": [
    "store_fw = defaultdict()\n",
    "print(\"Testing FluWatch data!\\n\")\n",
    "store_fw = test_against_all('fluwatch',['fluwatch','goviral','hongkong','hutterite'],data_,new_dataset_fluwatch,store_fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_fw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_hk = defaultdict()\n",
    "print(\"Testing Hongkong!\\n\")\n",
    "store_hk = test_against_all('hongkong',['hongkong','goviral','fluwatch','hutterite'],data_,new_dataset_hongkong,store_hk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_hk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ht = defaultdict()\n",
    "print(\"Testing hutterite!\\n\")\n",
    "store_ht = test_against_all('hutterite',['hutterite','goviral','fluwatch','hongkong'],data_,new_dataset_hutterite,store_ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
