{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The symptoms included are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['intercept','fever','sorethroat','cough','muscle','headache','fatigue','vomit','nausea','diarrhea','chills','sneeze','shortness of breath','phlegm','blockednose','earache','leg pain','runnynose','virus']\n",
    "age = ['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']\n",
    "gender = ['male','female']\n",
    "\n",
    "aucs_ = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'fever', 'sorethroat', 'cough', 'muscle', 'headache', 'fatigue', 'vomit', 'nausea', 'diarrhea', 'chills', 'sneeze', 'shortness of breath', 'phlegm', 'blockednose', 'earache', 'leg pain', 'runnynose', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data['intercept'] = 1\n",
    "    columns = list(data.columns)\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    data = data[columns]\n",
    "#     train_data = data.drop(['virus'],axis =1).as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_parameters(filename):\n",
    "    parameters = pd.read_csv(filename)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the parameters for the different dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_ = \"./Generated_Parameters_5/\"\n",
    "with_demographics_ = ['with_demographics_nyumc.csv','with_demographics_goviral.csv','with_demographics_fluwatch.csv','with_demographics_hongkong.csv','with_demographics_hutterite.csv']\n",
    "with_demographic_parameters = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_parameters(file,parameters_of):\n",
    "    param = read_parameters(file)\n",
    "    parameter_dict = defaultdict()\n",
    "    for i in parameters_of:\n",
    "        parameter_dict[i] = list(param[i])\n",
    "    return parameter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters(dataset_name,parameters):\n",
    "    return np.array(list(parameters[dataset_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(param,sample_points):\n",
    "    return sigmoid(np.dot(param,sample_points.T)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results_for_finding_threshold(filename,dataframe,predicted):\n",
    "    results = pd.DataFrame()\n",
    "    results['Actual'] = dataframe['virus']\n",
    "    results['Predicted'] = predicted\n",
    "    print(results.head())\n",
    "    results.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_datasets(training_data_,training_directory):\n",
    "    datasets = defaultdict()\n",
    "    for i in training_data_:\n",
    "        data = read_file(training_directory+i)\n",
    "        datasets[i[:-4]] = (data)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_results(data_dict,param):\n",
    "    results = defaultdict()\n",
    "    for i in list(param.keys()):\n",
    "        data,train = data_dict[i]\n",
    "        results[i] = get_results(param[i],train)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_statistics(list_):\n",
    "#     print(\"Min : \",min(list_))\n",
    "#     print(\"Max : \",max(list_))\n",
    "#     print(\"Mean : \",np.mean(list_))\n",
    "#     print(\"Standard Deviation : \",np.std(list_))\n",
    "    return min(list_),max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_class(threshold,list_):\n",
    "    ans = [1 if x >= threshold else 0 for x in list_]\n",
    "    return ans\n",
    "\n",
    "def metrics_pred(list1,list2):\n",
    "    f1 =f1_score(list1,list2)\n",
    "    precision = precision_score(list1,list2)\n",
    "    recall = recall_score(list1,list2)\n",
    "    accuracy = accuracy_score(list1,list2)\n",
    "    fpr,tpr,threshold = roc_curve(list1,list2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "#     print(\"f1 score : \",f1)\n",
    "#     print(\"Precision score : \",precision)\n",
    "#     print(\"Recall : \",recall)\n",
    "#     print(\"Accuracy : \",accuracy)\n",
    "#     print(\"Area under the curve : \",auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_threshold(min_,max_,list1,list2,step_size = 1e-3):\n",
    "    auc_thresholds = defaultdict()\n",
    "    value = min_\n",
    "    while value < max_:\n",
    "        auc_thresholds[value] = metrics_pred(list1,return_class(value,list2))\n",
    "        value += step_size\n",
    "    optimal_threshold = max(auc_thresholds.items(), key=lambda x: x[1]) \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_threshold(pred,true):\n",
    "    min_,max_ = result_statistics(pred)\n",
    "    threshold = find_threshold(min_,max_,true,pred)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_all_thresholds(results,data,y_true):\n",
    "    thresholds = defaultdict()\n",
    "    for i in list(data.keys()):\n",
    "        print(\"_____________________\")\n",
    "        min_,max_ = result_statistics(results[i])\n",
    "        \n",
    "        threshold = find_threshold(min_,max_,y_true[i],results[i])\n",
    "        print(\"Found threshold for : \",i)\n",
    "        thresholds[i] = threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(filename_,param,thresholds_):\n",
    "    aucs = defaultdict()\n",
    "    data,train = read_file(filename_)\n",
    "    for i in list(param.keys()):\n",
    "        test_results = get_results(param[i],train)\n",
    "        auc_ = metrics_pred(data['virus'],return_class(thresholds_[i][0],test_results))\n",
    "        aucs[i] = auc_\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_final_auc_scores(training_data_,training_directory,filename_,parameters):\n",
    "    data = get_all_datasets(training_data_)\n",
    "    results = get_all_results(data,parameters)\n",
    "    #find the thresholds\n",
    "    thresholds = return_all_thresholds(results,data)\n",
    "    #get the auc values\n",
    "    aucs_= test(filename_,parameters,thresholds)\n",
    "    return aucs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict(dict_):\n",
    "    temp = []\n",
    "    for k,v in dict_.items():\n",
    "        temp.append((k,v))\n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_symp = defaultdict()\n",
    "results_demo = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gender(dataframe_):\n",
    "    df = dataframe_[['male','female']]\n",
    "    temp = df.apply(lambda x:x.argmax(),axis =1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(dataframe_):\n",
    "    df = dataframe_[['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']]\n",
    "    temp = df.apply(lambda x: x.argmax(), axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_all(name,train,only_gender_data,only_age_data,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "#     for i in range(train.shape[0]):\n",
    "    for i in range(0,1):\n",
    "        result = []\n",
    "        sample_point = train[i,:]\n",
    "        p_data = [get_results(param_dict[name],sample_point)]\n",
    "        result.append(p_data)\n",
    "        print(\"Data : \",p_data)\n",
    "        p_collection = [get_results(param_dict[collection_mode],sample_point)]\n",
    "        print('Collection : ',p_collection)\n",
    "        result.append(p_collection)\n",
    "        gender = only_gender_data.iloc[i][:]\n",
    "        age = only_age_data.loc[i][:]\n",
    "        p_gender = [gender['male']*get_results(param_dict['male'] ,sample_point),gender['female']*get_results(param_dict['female'] ,sample_point) ]\n",
    "        print(\"Gender :\",p_gender)\n",
    "        p_age = [age['age 0-4']*get_results(param_dict['age 0-4'] ,sample_point),\n",
    "                 age['age 5-15']*get_results(param_dict['age 5-15'] ,sample_point),\n",
    "                 age['age 16-44']* get_results(param_dict['age 16-44'] ,sample_point),\n",
    "                 age['age 45-64']*get_results(param_dict['age 45-64'] ,sample_point),\n",
    "                 age['age 65+']*get_results(param_dict['age 65+'] ,sample_point)]\n",
    "#         p_population = get_results(param_dict[population],sample_point)\n",
    "        print(\"Age : \",p_age)\n",
    "        result = [p_data] + [p_collection] + [p_gender] +[p_age]\n",
    "        print(\"Final result : \",result)\n",
    "#         result = [p_data,p_collection,p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coeff(X,Y):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 10)\n",
    "    lm.fit(x_train,y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "#     print(\"Accuracy :\",acc)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "#     print(\"AUC :\",auc_score)\n",
    "    coefficients = lm.coef_.tolist()[0]\n",
    "    print(\"Coefficients : \",coefficients)\n",
    "    intercept = lm.intercept_.tolist()[0]\n",
    "    return coefficients,intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(list_):\n",
    "    min_ = min(list_)\n",
    "    max_ = max(list_)\n",
    "    denom = max_ - min_\n",
    "    ans = [x-min_/denom for x in list_]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION_MODE = {'nyumc':'clinically_collected',\n",
    "                   'goviral':'individually_reported',\n",
    "                   'fluwatch':'individually_reported',\n",
    "                   'hongkong': 'health_worker',\n",
    "                   'hutterite':'health_worker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicitions = [prediction_dataset,\n",
    "#                 prediction_collection_mode,\n",
    "#                 predicition_male,\n",
    "#                 prediction_female,\n",
    "#                 prediction_age0-4,\n",
    "#                 prediction_age5-15,\n",
    "#                 prediction_age6-44,\n",
    "#                 prediction_age45-64,\n",
    "#                 prediction_age65+]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        only_age_data = data_[age]\n",
    "        only_gender_data = data_[gender]\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_all(i,train_data_symp,only_gender_data,only_age_data,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        print(prediction)\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid token (<ipython-input-68-5425f3a136ac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-5425f3a136ac>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    nyid@nationalgrid.com 0232053636\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
     ]
    }
   ],
   "source": [
    "nyid@nationalgrid.com 0232053636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for HongKong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['nyumc.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'nyumc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [ 'nyumc', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics_goviral.csv',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With demographics!\n"
     ]
    }
   ],
   "source": [
    "print(\"With demographics!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyumc.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Data :  [[0.4131297785795559]]\n",
      "Collection :  [[0.31545297259793503]]\n",
      "Gender : [0.36369572312417436, 0.0]\n",
      "Age :  [0.0, 0.3640005953384614, 0.0, 0.0, 0.0]\n",
      "Final result :  [[[0.4131297785795559]], [[0.31545297259793503]], [0.36369572312417436, 0.0], [0.0, 0.3640005953384614, 0.0, 0.0, 0.0]]\n",
      "[[[[0.4131297785795559]], [[0.31545297259793503]], [0.36369572312417436, 0.0], [0.0, 0.3640005953384614, 0.0, 0.0, 0.0]]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 21907]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-f7d518df015a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresholds_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_nyumc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdemo_nyumc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-c3b5a16b0e5c>\u001b[0m in \u001b[0;36mprocess_all\u001b[0;34m(training_data_list, training_directory, filename_, parameters, collection_mode)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'virus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcoefficient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coeff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcoefficient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-d27fcd7fa90f>\u001b[0m in \u001b[0;36mget_coeff\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_coeff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         cv = StratifiedShuffleSplit(stratify, test_size=test_size,\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 173\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 21907]"
     ]
    }
   ],
   "source": [
    "weights_all,thresholds_all,prediction_all = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'nyumc': 0.70308413882679366})"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-13.374995305463436, 4.172228255717748, 7.069313833670369]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_all['nyumc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demographic level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyumc.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [8.441103973703346]\n",
      "Found threshold for  nyumc\n"
     ]
    }
   ],
   "source": [
    "weights_demographic,thresholds_demographic,prediction_demographic = process_demographic(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.441103973703346]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_demographic['nyumc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'nyumc': 0.56501044335588047})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_demographic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collection level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyumc.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [14.637663901470939]\n",
      "Found threshold for  nyumc\n"
     ]
    }
   ],
   "source": [
    "weights_collection,thresholds_collection,prediction_collection = process_collection(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.637663901470939]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_collection['nyumc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'nyumc': 0.40504697887531044})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyumc.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Found threshold for  nyumc\n"
     ]
    }
   ],
   "source": [
    "weights_dataset,thresholds_dataset,prediction_dataset = process_only_dataset(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'nyumc': 0.49808848602681988})"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['Predicted_Value_All'] = [i[1] for i in prediction_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Collection'] = [i[1] for i in prediction_collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Demographic'] = [i[1] for i in prediction_demographic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Predicted_Value_Dataset'] = [i[1] for i in prediction_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['True'] = [i[0] for i in prediction_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value_All</th>\n",
       "      <th>Predicted_Value_Collection</th>\n",
       "      <th>Predicted_Value_Demographic</th>\n",
       "      <th>Predicted_Value_Dataset</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.413130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.363979</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.037608</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033060</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.030729</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.469584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.033060</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008726</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.413130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.038457</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.030736</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.469507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Value_All  Predicted_Value_Collection  \\\n",
       "0             0.008524                    0.004458   \n",
       "1             0.000149                    0.000122   \n",
       "2             0.032877                    0.040791   \n",
       "3             0.033060                    0.040791   \n",
       "4             0.033501                    0.040791   \n",
       "5             0.030729                    0.023143   \n",
       "6             0.033060                    0.040791   \n",
       "7             0.008726                    0.004458   \n",
       "8             0.033500                    0.040791   \n",
       "9             0.030736                    0.023671   \n",
       "\n",
       "   Predicted_Value_Demographic  Predicted_Value_Dataset  True  \n",
       "0                     0.004193                 0.413130     0  \n",
       "1                     0.000052                 0.363979     0  \n",
       "2                     0.037608                 0.497823     0  \n",
       "3                     0.037858                 0.497823     0  \n",
       "4                     0.038458                 0.497823     0  \n",
       "5                     0.027188                 0.469584     1  \n",
       "6                     0.037858                 0.497823     0  \n",
       "7                     0.004312                 0.413130     0  \n",
       "8                     0.038457                 0.497823     0  \n",
       "9                     0.026957                 0.469507     0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Dataset_Specific'] = weights_all['nyumc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Collection_Mode'] = weights_all['nyumc'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions['Only_Dataset'] = weights_dataset['nyumc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['All_Demographic'] = weights_all['nyumc'][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Only_Collection'] = weights_collection['nyumc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions['Only_Demographic'] = weights_demographic['nyumc'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Value_All</th>\n",
       "      <th>Predicted_Value_Collection</th>\n",
       "      <th>Predicted_Value_Demographic</th>\n",
       "      <th>Predicted_Value_Dataset</th>\n",
       "      <th>True</th>\n",
       "      <th>All_Dataset_Specific</th>\n",
       "      <th>All_Collection_Mode</th>\n",
       "      <th>All_Demographic</th>\n",
       "      <th>Only_Collection</th>\n",
       "      <th>Only_Demographic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.413130</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.363979</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.037608</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033060</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.038458</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.030729</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.469584</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.033060</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.037858</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008726</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.413130</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>0.038457</td>\n",
       "      <td>0.497823</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.030736</td>\n",
       "      <td>0.023671</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>0.469507</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.374995</td>\n",
       "      <td>4.172228</td>\n",
       "      <td>7.069314</td>\n",
       "      <td>14.637664</td>\n",
       "      <td>8.441104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Value_All  Predicted_Value_Collection  \\\n",
       "0             0.008524                    0.004458   \n",
       "1             0.000149                    0.000122   \n",
       "2             0.032877                    0.040791   \n",
       "3             0.033060                    0.040791   \n",
       "4             0.033501                    0.040791   \n",
       "5             0.030729                    0.023143   \n",
       "6             0.033060                    0.040791   \n",
       "7             0.008726                    0.004458   \n",
       "8             0.033500                    0.040791   \n",
       "9             0.030736                    0.023671   \n",
       "\n",
       "   Predicted_Value_Demographic  Predicted_Value_Dataset  True  \\\n",
       "0                     0.004193                 0.413130     0   \n",
       "1                     0.000052                 0.363979     0   \n",
       "2                     0.037608                 0.497823     0   \n",
       "3                     0.037858                 0.497823     0   \n",
       "4                     0.038458                 0.497823     0   \n",
       "5                     0.027188                 0.469584     1   \n",
       "6                     0.037858                 0.497823     0   \n",
       "7                     0.004312                 0.413130     0   \n",
       "8                     0.038457                 0.497823     0   \n",
       "9                     0.026957                 0.469507     0   \n",
       "\n",
       "   All_Dataset_Specific  All_Collection_Mode  All_Demographic  \\\n",
       "0            -13.374995             4.172228         7.069314   \n",
       "1            -13.374995             4.172228         7.069314   \n",
       "2            -13.374995             4.172228         7.069314   \n",
       "3            -13.374995             4.172228         7.069314   \n",
       "4            -13.374995             4.172228         7.069314   \n",
       "5            -13.374995             4.172228         7.069314   \n",
       "6            -13.374995             4.172228         7.069314   \n",
       "7            -13.374995             4.172228         7.069314   \n",
       "8            -13.374995             4.172228         7.069314   \n",
       "9            -13.374995             4.172228         7.069314   \n",
       "\n",
       "   Only_Collection  Only_Demographic  \n",
       "0        14.637664          8.441104  \n",
       "1        14.637664          8.441104  \n",
       "2        14.637664          8.441104  \n",
       "3        14.637664          8.441104  \n",
       "4        14.637664          8.441104  \n",
       "5        14.637664          8.441104  \n",
       "6        14.637664          8.441104  \n",
       "7        14.637664          8.441104  \n",
       "8        14.637664          8.441104  \n",
       "9        14.637664          8.441104  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.to_csv(\"../Predictions/predictions_nyumc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
