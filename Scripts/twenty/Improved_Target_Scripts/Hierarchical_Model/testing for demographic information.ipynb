{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score,roc_curve\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "random.seed(1)\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The symptoms included are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symptoms = ['intercept',\n",
    "            'fever',\n",
    "            'sorethroat',\n",
    "            'cough',\n",
    "            'muscle',\n",
    "            'headache',\n",
    "            'fatigue',\n",
    "            'vomit',\n",
    "            'nausea',\n",
    "            'diarrhea',\n",
    "            'chills',\n",
    "            'sneeze',\n",
    "            'shortness of breath',\n",
    "            'phlegm',\n",
    "            'blockednose',\n",
    "            'earache',\n",
    "            'leg pain',\n",
    "            'runnynose',\n",
    "            'virus']\n",
    "aucs_ = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['intercept', 'fever', 'sorethroat', 'cough', 'muscle', 'headache', 'fatigue', 'vomit', 'nausea', 'diarrhea', 'chills', 'sneeze', 'shortness of breath', 'phlegm', 'blockednose', 'earache', 'leg pain', 'runnynose', 'virus']\n"
     ]
    }
   ],
   "source": [
    "print(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data['intercept'] = 1\n",
    "    columns = list(data.columns)\n",
    "    columns = columns[-1:] + columns[:-1]\n",
    "    data = data[columns]\n",
    "#     train_data = data.drop(['virus'],axis =1).as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_parameters(filename):\n",
    "    parameters = pd.read_csv(filename)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the parameters for the different dataset combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory_ = \"./Generated_Parameters_Gender/\"\n",
    "with_demographics_ = ['with_demographics.csv']\n",
    "with_demographic_parameters = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_parameters(file,parameters_of):\n",
    "    param = read_parameters(file)\n",
    "    parameter_dict = defaultdict()\n",
    "    for i in parameters_of:\n",
    "        parameter_dict[i] = list(param[i])\n",
    "    return parameter_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parameters(dataset_name,parameters):\n",
    "    return np.array(list(parameters[dataset_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(param,sample_points):\n",
    "    return sigmoid(np.dot(param,sample_points.T)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_results_for_finding_threshold(filename,dataframe,predicted):\n",
    "    results = pd.DataFrame()\n",
    "    results['Actual'] = dataframe['virus']\n",
    "    results['Predicted'] = predicted\n",
    "    print(results.head())\n",
    "    results.to_csv(filename,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_datasets(training_data_,training_directory):\n",
    "    datasets = defaultdict()\n",
    "    for i in training_data_:\n",
    "        data = read_file(training_directory+i)\n",
    "        datasets[i[:-4]] = (data)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_results(data_dict,param):\n",
    "    results = defaultdict()\n",
    "    for i in list(param.keys()):\n",
    "        data,train = data_dict[i]\n",
    "        results[i] = get_results(param[i],train)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_statistics(list_):\n",
    "#     print(\"Min : \",min(list_))\n",
    "#     print(\"Max : \",max(list_))\n",
    "#     print(\"Mean : \",np.mean(list_))\n",
    "#     print(\"Standard Deviation : \",np.std(list_))\n",
    "    return min(list_),max(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_class(threshold,list_):\n",
    "    ans = [1 if x >= threshold else 0 for x in list_]\n",
    "    return ans\n",
    "\n",
    "def metrics_pred(list1,list2):\n",
    "    f1 =f1_score(list1,list2)\n",
    "    precision = precision_score(list1,list2)\n",
    "    recall = recall_score(list1,list2)\n",
    "    accuracy = accuracy_score(list1,list2)\n",
    "    fpr,tpr,threshold = roc_curve(list1,list2)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "#     print(\"f1 score : \",f1)\n",
    "#     print(\"Precision score : \",precision)\n",
    "#     print(\"Recall : \",recall)\n",
    "#     print(\"Accuracy : \",accuracy)\n",
    "#     print(\"Area under the curve : \",auc)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_threshold(min_,max_,list1,list2,step_size = 1e-3):\n",
    "    auc_thresholds = defaultdict()\n",
    "    value = min_\n",
    "    while value < max_:\n",
    "        auc_thresholds[value] = metrics_pred(list1,return_class(value,list2))\n",
    "        value += step_size\n",
    "    optimal_threshold = max(auc_thresholds.items(), key=lambda x: x[1]) \n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_threshold(pred,true):\n",
    "    min_,max_ = result_statistics(pred)\n",
    "    threshold = find_threshold(min_,max_,true,pred)\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_all_thresholds(results,data,y_true):\n",
    "    thresholds = defaultdict()\n",
    "    for i in list(data.keys()):\n",
    "        print(\"_____________________\")\n",
    "        min_,max_ = result_statistics(results[i])\n",
    "        \n",
    "        threshold = find_threshold(min_,max_,y_true[i],results[i])\n",
    "        print(\"Found threshold for : \",i)\n",
    "        thresholds[i] = threshold\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test(filename_,param,thresholds_):\n",
    "    aucs = defaultdict()\n",
    "    data,train = read_file(filename_)\n",
    "    for i in list(param.keys()):\n",
    "        test_results = get_results(param[i],train)\n",
    "        auc_ = metrics_pred(data['virus'],return_class(thresholds_[i][0],test_results))\n",
    "        aucs[i] = auc_\n",
    "    return aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_final_auc_scores(training_data_,training_directory,filename_,parameters):\n",
    "    data = get_all_datasets(training_data_)\n",
    "    results = get_all_results(data,parameters)\n",
    "    #find the thresholds\n",
    "    thresholds = return_all_thresholds(results,data)\n",
    "    #get the auc values\n",
    "    aucs_= test(filename_,parameters,thresholds)\n",
    "    return aucs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dict(dict_):\n",
    "    temp = []\n",
    "    for k,v in dict_.items():\n",
    "        temp.append((k,v))\n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_symp = defaultdict()\n",
    "results_demo = defaultdict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gender(dataframe_):\n",
    "    df = dataframe_[['male','female']]\n",
    "    temp = df.apply(lambda x:x.argmax(),axis =1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_age(dataframe_):\n",
    "    df = dataframe_[['age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+']]\n",
    "    temp = df.apply(lambda x: x.argmax(), axis=1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions_all(name,train,only_symp_age,only_symp_gender,param_dict,temp_age,temp_gender,collection_mode = 'clinically_collected',population ='population'):\n",
    "    results = []\n",
    "    for i in range(train.shape[0]):\n",
    "        result = []\n",
    "        sample_point = train[i,:]\n",
    "        gender = list(only_symp_gender.iloc[i][:])\n",
    "        age = list(only_symp_age.iloc[i][:])\n",
    "        p_data = get_results(param_dict[name],sample_point)\n",
    "        result.append(p_data)\n",
    "        result.append(gender[0]*get_results(param_dict['male'],sample_point))\n",
    "        result.append(gender[1]*get_results(param_dict['female'],sample_point))\n",
    "\n",
    "#         result.append(age[0]*get_results(param_dict['age 0-4'],sample_point))\n",
    "#         result.append(age[1]*get_results(param_dict['age 5-15'],sample_point))\n",
    "#         result.append(age[2]*get_results(param_dict['age 16-44'],sample_point))\n",
    "#         result.append(age[3]*get_results(param_dict['age 45-64'],sample_point))\n",
    "#         result.append(age[4]*get_results(param_dict['age 65+'],sample_point))\n",
    "        \n",
    "#         p_collection = get_results(param_dict[collection_mode],sample_point)\n",
    "#         p_gender = get_results(param_dict[temp_gender[i]],sample_point)\n",
    "#         p_age = get_results(param_dict[temp_age[i]],sample_point)\n",
    "# #         p_population = get_results(param_dict[population],sample_point)\n",
    "#         result = [p_data,p_collection,p_gender+p_age]\n",
    "        results.append(result)\n",
    "    return results\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coeff(X,Y):\n",
    "    lm = linear_model.LogisticRegression()\n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 10)\n",
    "    lm.fit(x_train,y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "#     print(\"Accuracy :\",acc)\n",
    "    fpr,tpr,threshold = roc_curve(y_test,y_pred)\n",
    "    auc_score = metrics.auc(fpr,tpr)\n",
    "#     print(\"AUC :\",auc_score)\n",
    "    coefficients = lm.coef_.tolist()[0]\n",
    "    print(\"Coefficients : \",coefficients)\n",
    "    intercept = lm.intercept_.tolist()[0]\n",
    "    return coefficients,intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(list_):\n",
    "    min_ = min(list_)\n",
    "    max_ = max(list_)\n",
    "    denom = max_ - min_\n",
    "    ans = [x-min_/denom for x in list_]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLLECTION_MODE = {'nyumc':'clinically_collected',\n",
    "                   'goviral':'individually_reported',\n",
    "                   'fluwatch':'individually_reported',\n",
    "                   'hongkong': 'health_worker',\n",
    "                   'hutterite':'health_worker'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_all(training_data_list,training_directory,filename_,parameters,collection_mode = COLLECTION_MODE):\n",
    "    name_dataset = filename_.split('/')[-1]\n",
    "    thresholds = defaultdict()\n",
    "    print(name_dataset)\n",
    "    data = get_all_datasets(training_data_list,training_directory)\n",
    "    print(\"Got the data\")\n",
    "    print(\"Now finding coefficients for the the datasets!\")\n",
    "    weights = defaultdict()\n",
    "    for i in data.keys():\n",
    "        print(\"Analyzing the dataset : \",i)\n",
    "        data_ = data[i]\n",
    "        temp_age = get_age(data_)\n",
    "        temp_gender = get_gender(data_)\n",
    "        only_symp_data = data_[symptoms]\n",
    "        only_symp_gender = data_[['male','female']]\n",
    "        only_symp_age = data_[['age 0-4','age 5-15','age 16-44','age 45-64','age 65+']]\n",
    "        only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "        train_data_symp = only_symp_data.as_matrix()\n",
    "        prediction = get_predictions_all(i,train_data_symp,only_symp_age,only_symp_gender,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "        y_true = list(data_['virus'])\n",
    "        coefficient,intercept = get_coeff(prediction,y_true)\n",
    "        weights[i] = (coefficient,intercept)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(j) for j in value]\n",
    "        threshold = get_threshold(values,y_true)\n",
    "        print(\"Found threshold for \",i)\n",
    "        thresholds[i] = threshold[0]\n",
    "        ans = [(y_true[i],values[i]) for i in range(len(y_true))]\n",
    "    return weights,thresholds,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test(training_directory,filename_,parameters,weights,thresholds,collection_mode = COLLECTION_MODE):\n",
    "    aucs_ = defaultdict()\n",
    "    predictions = defaultdict()\n",
    "    test_data = get_all_datasets([filename_],training_directory)\n",
    "    name = filename_.split('.')[0]\n",
    "    print(\"Name : \",name) \n",
    "    data_ = test_data[name]\n",
    "    temp_age = get_age(data_)\n",
    "    temp_gender = get_gender(data_)\n",
    "    only_symp_data = data_[symptoms]\n",
    "    only_symp_data.drop('virus',axis = 1,inplace = True)\n",
    "    only_symp_gender = data_[['male','female']]\n",
    "    only_symp_age = data_[['age 0-4','age 5-15','age 16-44','age 45-64','age 65+']]\n",
    "    y_true = list(data_['virus'])\n",
    "    train_data_symp = only_symp_data.as_matrix()\n",
    "    for i in weights.keys():\n",
    "        print(\"Using the parameters of : \",i)\n",
    "        prediction = get_predictions(i,train_data_symp,only_symp_age,only_symp_gender,parameters,temp_age,temp_gender,COLLECTION_MODE[i])\n",
    "#         temp = [i[1:] for i in prediction]\n",
    "#         first = [i[0] for i in prediction]\n",
    "#         prediction = np.array(temp)\n",
    "        value = np.array(np.dot(prediction,np.array(weights[i][0]).T)+weights[i][1])\n",
    "        values = [sigmoid(i) for i in value]\n",
    "        predictions[i] = values\n",
    "    print(\"Got the predicitions from the different parameters\")\n",
    "    for i in weights.keys():\n",
    "        auc_ = metrics_pred(y_true,return_class(0.5,predictions[i]))\n",
    "        aucs_[i] = auc_\n",
    "        print(\"Found the auc for \",i)\n",
    "    return aucs_\n",
    "#         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for NYUMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_nyumc = ['goviral.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/Train/\"\n",
    "filename_ = 'goviral.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['population', 'female', 'health_worker', 'individually_reported', 'goviral', 'male'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['goviral',  'individually_reported', 'health_worker', 'female', 'male', 'population']\n",
    "demo_nyumc = return_parameters(directory_+'with_demographics.csv',cols)\n",
    "demo_nyumc.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With demographics!\n"
     ]
    }
   ],
   "source": [
    "print(\"With demographics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goviral.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [0.02030731602793506, -0.9042766296957566, -0.6678832577069207]\n",
      "Found threshold for  goviral\n"
     ]
    }
   ],
   "source": [
    "weights_nyumc,thresholds_nyumc,pred = process_all(training_data_nyumc,training_directory,filename_,demo_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'goviral': 0.5084155702927263})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  goviral\n",
      "Using the parameters of :  goviral\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  goviral\n"
     ]
    }
   ],
   "source": [
    "aucs_nyumc = process_test(training_directory,filename_,demo_nyumc,weights_nyumc,thresholds_nyumc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'goviral': 0.5600631782152155})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_nyumc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['goviral'] = aucs_nyumc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Generating the results for Goviral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_goviral = ['fluwatch.csv']\n",
    "training_directory = \"../../Data/Symptoms_Demo/Balanced_Data/Train/\"\n",
    "filename_ = 'fluwatch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['population', 'female', 'health_worker', 'fluwatch', 'individually_reported', 'male'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['fluwatch',  'individually_reported', 'health_worker', 'female', 'male', 'population']\n",
    "demo_goviral = return_parameters(directory_+'with_demographics.csv',cols)\n",
    "demo_goviral.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluwatch.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [-0.08753470432834394, 0.6870392820838427, -0.598233486252406]\n",
      "Found threshold for  fluwatch\n"
     ]
    }
   ],
   "source": [
    "weights_goviral,thresholds_goviral,ans = process_all(training_data_goviral,training_directory,filename_,demo_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  fluwatch\n",
      "Using the parameters of :  fluwatch\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  fluwatch\n"
     ]
    }
   ],
   "source": [
    "aucs_goviral1 = process_test(training_directory,filename_,demo_goviral,weights_goviral,thresholds_goviral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'fluwatch': 0.5627334744765937})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_goviral1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['nyumc'] = aucs_goviral1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Generating the results for fluwatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_fluwatch = ['hongkong.csv']\n",
    "# training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hongkong.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['population', 'female', 'health_worker', 'individually_reported', 'male', 'hongkong'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['hongkong',  'individually_reported', 'health_worker', 'female', 'male', 'population']\n",
    "demo_fluwatch = return_parameters(directory_+'with_demographics.csv',cols)\n",
    "demo_fluwatch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hongkong.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [-2.7353799081259553, 0.6334031753558652, -0.15086377246350496]\n",
      "Found threshold for  hongkong\n"
     ]
    }
   ],
   "source": [
    "weights_fluwatch,thresholds_fluwatch,ans = process_all(training_data_fluwatch,training_directory,filename_,demo_fluwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  hongkong\n",
      "Using the parameters of :  hongkong\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  hongkong\n"
     ]
    }
   ],
   "source": [
    "aucs_fluwatch1 = process_test(training_directory,filename_,demo_fluwatch,weights_fluwatch,thresholds_fluwatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hongkong': 0.5402705476372813})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_fluwatch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['hongkong'] = aucs_fluwatch1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating the results for HongKong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_hongkong = ['hutterite.csv']\n",
    "# training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'hutterite.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['population', 'female', 'health_worker', 'hutterite', 'individually_reported', 'male'])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['hutterite',  'individually_reported', 'health_worker', 'female', 'male', 'population']\n",
    "demo_hongkong = return_parameters(directory_+'with_demographics.csv',cols)\n",
    "demo_hongkong.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hutterite.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  hutterite\n",
      "Coefficients :  [0.10271714236920669, 1.0339273126757536, -0.12552082350009386]\n",
      "Found threshold for  hutterite\n"
     ]
    }
   ],
   "source": [
    "weights_hongkong,thresholds_hongkong,ans = process_all(training_data_hongkong,training_directory,filename_,demo_hongkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  hutterite\n",
      "Using the parameters of :  hutterite\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  hutterite\n"
     ]
    }
   ],
   "source": [
    "aucs_hongkong = process_test(training_directory,filename_,demo_hongkong,weights_hongkong,thresholds_hongkong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'hutterite': 0.5396825396825397})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_hongkong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['hutterite'] = aucs_hongkong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generating results for hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_hutterite = ['nyumc.csv','goviral.csv','fluwatch.csv','hongkong.csv']\n",
    "training_directory = \"../../Data/With_Improved_Target/With_Demographics/\"\n",
    "filename_ = 'fluwatch.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['nyumc', 'goviral', 'fluwatch', 'hongkong', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population'])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['nyumc', 'goviral', 'fluwatch', 'hongkong', 'clinically_collected', 'individually_reported', 'health_worker', 'female', 'male', 'age 0-4', 'age 5-15', 'age 16-44', 'age 45-64', 'age 65+', 'population']\n",
    "demo_hutterite = return_parameters(directory_+'with_demographics_hutterite.csv',cols)\n",
    "demo_hutterite.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fluwatch.csv\n",
      "Got the data\n",
      "Now finding coefficients for the the datasets!\n",
      "Analyzing the dataset :  nyumc\n",
      "Coefficients :  [12.135089069195635]\n",
      "Found threshold for  nyumc\n",
      "Analyzing the dataset :  goviral\n",
      "Coefficients :  [2.7022152775205974]\n",
      "Found threshold for  goviral\n",
      "Analyzing the dataset :  fluwatch\n",
      "Coefficients :  [1.7454702766983732]\n",
      "Found threshold for  fluwatch\n",
      "Analyzing the dataset :  hongkong\n",
      "Coefficients :  [10.983963939432357]\n",
      "Found threshold for  hongkong\n"
     ]
    }
   ],
   "source": [
    "weights_hutterite,thresholds_hutterite = process(training_data_hutterite,training_directory,filename_,demo_hutterite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name :  fluwatch\n",
      "Using the parameters of :  nyumc\n",
      "Using the parameters of :  goviral\n",
      "Using the parameters of :  fluwatch\n",
      "Using the parameters of :  hongkong\n",
      "Got the predicitions from the different parameters\n",
      "Found the auc for  nyumc\n",
      "Found the auc for  goviral\n",
      "Found the auc for  fluwatch\n",
      "Found the auc for  hongkong\n"
     ]
    }
   ],
   "source": [
    "aucs_hutterite = process_test(training_directory,filename_,demo_hutterite,weights_hutterite,thresholds_hutterite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': 0.5424190141181644,\n",
       "             'goviral': 0.54253132856036779,\n",
       "             'hongkong': 0.52050097020560715,\n",
       "             'nyumc': 0.50119483449152624})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aucs_['fluwatch'] = aucs_hutterite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'fluwatch': defaultdict(None,\n",
       "                         {'fluwatch': 0.5424190141181644,\n",
       "                          'goviral': 0.54253132856036779,\n",
       "                          'hongkong': 0.52050097020560715,\n",
       "                          'nyumc': 0.50119483449152624}),\n",
       "             'goviral': defaultdict(None,\n",
       "                         {'fluwatch': 0.59736032196969702,\n",
       "                          'goviral': 0.61943655303030298,\n",
       "                          'hongkong': 0.64405776515151514,\n",
       "                          'hutterite': 0.64607007575757569}),\n",
       "             'hongkong': defaultdict(None,\n",
       "                         {'goviral': 0.67409301993119553,\n",
       "                          'hongkong': 0.86103136942038738,\n",
       "                          'hutterite': 0.85938388687517098,\n",
       "                          'nyumc': 0.51079817781590009}),\n",
       "             'hutterite': defaultdict(None,\n",
       "                         {'fluwatch': 0.5262923351158646,\n",
       "                          'goviral': 0.51099598930481283,\n",
       "                          'hutterite': 0.57973113487819372,\n",
       "                          'nyumc': 0.51924762329174101}),\n",
       "             'nyumc': defaultdict(None,\n",
       "                         {'fluwatch': 0.5,\n",
       "                          'hongkong': 0.54590970326164812,\n",
       "                          'hutterite': 0.5427801939659288,\n",
       "                          'nyumc': 0.61626304572294199})})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_plots(columns,dict_,name,order,label,title):\n",
    "    df = pd.DataFrame()\n",
    "    df_list = []\n",
    "    for i in columns:\n",
    "        print(i)\n",
    "        df_list.append(pd.DataFrame({k:[v] for (k,v) in dict(dict_[i]).items()}))\n",
    "    df = pd.concat(df_list)\n",
    "#     df.fillna(0,inplace = True)\n",
    "    df[name] = columns\n",
    "    df.set_index(name,inplace = True)\n",
    "    df = df[order]\n",
    "    print(df)\n",
    "    sns.set()\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(df,annot=True,linewidth = 0.8,ax = ax,cbar_kws = {'label' : label},fmt=\"f\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted using datatset')\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['fluwatch','hutterite','hongkong','nyumc','goviral'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['goviral','nyumc','hongkong','hutterite','fluwatch'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['nyumc','goviral','fluwatch','hongkong','hutterite'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['hutterite','hongkong','fluwatch','goviral','nyumc'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyumc = create_plots(['nyumc','goviral','fluwatch','hongkong','hutterite'], \n",
    "                     aucs_, \n",
    "                     'Dataset',\n",
    "                     ['hutterite','hongkong','fluwatch','goviral','nyumc'],'AUC Scores ','Hierarchical : AUC scores with demographics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
